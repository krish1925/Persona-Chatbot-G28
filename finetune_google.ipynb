{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "client = OpenAI(api_key='sk-proj-upQZZY0y4IHRDrTWeZ8LT3BlbkFJuQrWzh9GD9yO9FoFkqha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 50\n",
      "First example:\n",
      "{'role': 'system', 'content': \"I will be user 1, and you will be user 2. I will provide the personas for user 2 (which is you), and you have to infer the persona of user 2 through the context that is given afterwards. I will provide the first 6 lines of the conversation between the 2 users with the given persona. Given the persona of user 2 (your persona) and the beginning of the conversation, you will need to reply to my prompt as if you were that user, and take on that user's personality based on the description provided. Only reply with one line of conversation. Here is the persona for user 2, \"}\n",
      "{'role': 'user', 'content': \"User2 persona: My favorite drink is iced coffee.\\nI have a black belt in karate.\\nI m in a jazz band and play the saxophone.\\nI vacation along lake michigan every summer. Now here is the conversational context that you need to use: User 1: Hi! I'm [user 1's name].\\nUser 2: Hi [user 1's name], I'm [user 2's name].\\nUser 1: What do you do for fun?\\nUser 2: I like to play video games, go to the beach, and read.\\nUser 1: I like to play video games too! I'm not much of a reader, though.\\nUser 2: What video games do you like to play?\\nUser 1: I like to play a lot of different games, but I'm really into competitive online games right now.\"}\n",
      "{'role': 'assistant', 'content': \"User 2: I'm not really into competitive games, I like to play more relaxing games.\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "with open(\"Synthetic2.json\", 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-oGK817Tj9R4o5Jc3LYqhk0tj', bytes=67228, created_at=1717526808, filename='Synthetic2.json', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(r\"Synthetic2.json\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-zzSEtIuJkxoPe6a423Cly1fm', created_at=1717526811, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-GdQsAXKoKSopVYWBmvCm4E8q', result_files=[], status='validating_files', trained_tokens=None, training_file='file-lZdJq1mQ7WDzsGQthrlLWmMM', validation_file=None, user_provided_suffix=None, seed=1740635596, estimated_finish=None, integrations=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-lZdJq1mQ7WDzsGQthrlLWmMM\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-DzxyFAtFUr4F2tpoPO1XjLoI', created_at=1717278202, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-IxDL5Et8L4RziSBqlEvdma4J', created_at=1717278195, level='info', message='New fine-tuned model created: ft:gpt-3.5-turbo-0125:personal::9VQnLCvi', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-J5Bi1pAkSMTzoSwuYYFc3lWG', created_at=1717278195, level='info', message='Checkpoint created at step 1624 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal::9VQnLny0:ckpt-step-1624', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-hHsO0YhD4CARNLfWLNEpfOGw', created_at=1717278195, level='info', message='Checkpoint created at step 812 with Snapshot ID: ft:gpt-3.5-turbo-0125:personal::9VQnKimW:ckpt-step-812', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-G1ogl6AhL0y6n8ToBa7NtRUG', created_at=1717278189, level='info', message='Step 1626/1626: training loss=0.44', object='fine_tuning.job.event', data={'step': 1626, 'train_loss': 0.43924883008003235, 'total_steps': 1626, 'train_mean_token_accuracy': 0.8383620977401733}, type='metrics'), FineTuningJobEvent(id='ftevent-hjm8xd6Ixhuv66HDIPj7ny12', created_at=1717278189, level='info', message='Step 1625/1626: training loss=0.38', object='fine_tuning.job.event', data={'step': 1625, 'train_loss': 0.3778199851512909, 'total_steps': 1626, 'train_mean_token_accuracy': 0.859603226184845}, type='metrics'), FineTuningJobEvent(id='ftevent-TLRgLipmFBTWo6OCXkNNxqtG', created_at=1717278185, level='info', message='Step 1624/1626: training loss=0.31', object='fine_tuning.job.event', data={'step': 1624, 'train_loss': 0.3073161244392395, 'total_steps': 1626, 'train_mean_token_accuracy': 0.890304684638977}, type='metrics'), FineTuningJobEvent(id='ftevent-QHCpLfTSx6kd7mpg5XsFs295', created_at=1717278183, level='info', message='Step 1623/1626: training loss=0.31', object='fine_tuning.job.event', data={'step': 1623, 'train_loss': 0.3102280795574188, 'total_steps': 1626, 'train_mean_token_accuracy': 0.8868101239204407}, type='metrics'), FineTuningJobEvent(id='ftevent-vY8vgzWan5jLu6hOLgtOBEmQ', created_at=1717278179, level='info', message='Step 1622/1626: training loss=0.33', object='fine_tuning.job.event', data={'step': 1622, 'train_loss': 0.32853302359580994, 'total_steps': 1626, 'train_mean_token_accuracy': 0.8816986680030823}, type='metrics'), FineTuningJobEvent(id='ftevent-Nr1tCtsMuk317TRiCIcCMy90', created_at=1717278177, level='info', message='Step 1621/1626: training loss=0.37', object='fine_tuning.job.event', data={'step': 1621, 'train_loss': 0.36830100417137146, 'total_steps': 1626, 'train_mean_token_accuracy': 0.8635658621788025}, type='metrics')], object='list', has_more=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(\"ftjob-PvV5ISHY4cCCOOSxgoybRAk2\")\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-PvV5ISHY4cCCOOSxgoybRAk2\", limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "result = client.fine_tuning.jobs.list()\n",
    "fine_tuned_model = result.data[0].fine_tuned_model\n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      " User 1: Hi, I'm [user 1 name].\n",
      "User 2: Hello, I'm [user 2 name].\n",
      "User 1: What do you like to do for fun?\n",
      "User 2: I like to play video games, watch movies, and read books.\n",
      "User 1: Me too! What are some of your favorite video games?\n",
      "User 2: I like playing open world games like Grand Theft Auto, Skyrim, and The Witcher.\n",
      "User 1: I love those games too! I've spent so many hours playing them.\n",
      "User 2: I know, right? They're so much fun.\n",
      "User 1: So, what are you reading right now?\n",
      "User 2: I'm reading a fantasy novel called The Name of the Wind. It's really good.\n",
      "User 1: I've heard good things about that book. I'll have to check it out.\n",
      "User 2: You should, it's really well written.\n",
      "User 1: So, what do you do for work?\n",
      "User 2: I'm a software engineer.\n",
      "User 1: Oh, cool! I'm a software engineer too.\n",
      "User 2: Really? That's awesome! What kind of software do you work on?\n",
      "User 1: I work on web applications.\n",
      "User 2: Oh, cool! I've always wanted to learn how to make web applications.\n",
      "User 1: It's not too hard to learn. You just need to know a few programming languages and how to use some frameworks.\n",
      "User 2: I guess I'll have to look into it.\n",
      "User 1: You should! It's a lot of fun.\n",
      "User 2: I will! Thanks for the advice.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:personal::9VQnLCvi\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a chatbot with the goal of responding to my prompt. \\\n",
    "     I will be user 1, and you will be user 2. I will also provide the personas for both users. \\\n",
    "     Given the persona of user 2 (your persona), you will need to reply to my prompt as if you \\\n",
    "     were that user, and take on that user's personality based on the description provided.\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(f\"Response: \\n {completion.choices[0].message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs260r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
