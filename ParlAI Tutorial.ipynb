{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1bRMvN0lGXaTF5fuTidgvlAl-Lb41F7AD","timestamp":1717607369850}],"gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zsb-Cvf6lnVX"},"source":["<img src=\"https://parl.ai/docs/_static/img/parlai.png\" width=\"700\"/>\n","\n","**Author**: Stephen Roller ([GitHub](https://github.com/stephenroller), [Twitter](https://twitter.com/stephenroller))\n","\n","\n","# Welcome to the ParlAI interactive tutorial\n","\n","In this tutorial we will:\n","\n","- Chat with a neural network model!\n","- Show how to use common commands in ParlAI, like inspecting data and model outputs.\n","- See where to find information about many options.\n","- Show how to fine-tune a pretrained model on a specific task\n","- Add our own datasets to ParlAI\n","- And add our own models to ParlAI\n","\n","We won't be running any examples of using Amazon Mechanical Turk, or connecting to Chat services, but you can check out our [docs](https://parl.ai/docs/) for more information on these areas.\n","\n","**Note:** *Make sure you're running this session with a GPU attached.*"]},{"cell_type":"code","metadata":{"id":"t_bFnOWslsj9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717609411430,"user_tz":420,"elapsed":234,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}},"outputId":"e00f3d74-46cd-424d-dc8e-88aa1d982af9"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jun  5 17:43:31 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla V100-SXM2-16GB           Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0              23W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"jMxd1KIRl9Xm"},"source":["## Installing parlai\n","\n","We need to install ParlAI. Since we're in Google Colab, we can assume PyTorch and similar dependencies are installed already"]},{"cell_type":"code","metadata":{"id":"i93Mn_I7MOEO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717609549527,"user_tz":420,"elapsed":135663,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}},"outputId":"73d49022-a4c8-4bea-a781-511673a1c3f3"},"source":["!pip install -q parlai\n","!pip install -q subword_nmt # extra requirement we need for this tutorial"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.6/547.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.9/95.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.7/120.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.8/140.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.1/136.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.6/388.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.5/388.5 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.1/346.1 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.1/346.1 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","bigframes 1.8.0 requires fsspec>=2023.3.0, but you have fsspec 2022.2.0 which is incompatible.\n","chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","dopamine-rl 4.0.9 requires tqdm>=4.64.1, but you have tqdm 4.62.3 which is incompatible.\n","gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2022.2.0 which is incompatible.\n","jsonschema 4.19.2 requires attrs>=22.2.0, but you have attrs 20.2.0 which is incompatible.\n","pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n","referencing 0.35.1 requires attrs>=22.2.0, but you have attrs 20.2.0 which is incompatible.\n","transformers 4.41.2 requires huggingface-hub<1.0,>=0.23.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install --upgrade huggingface_hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swZfxIqTZS-t","executionInfo":{"status":"ok","timestamp":1717609562850,"user_tz":420,"elapsed":13335,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}},"outputId":"3f083930-386b-433b-8235-49b0cabd08cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.17.3)\n","Collecting huggingface_hub\n","  Using cached huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n","Collecting fsspec>=2023.5.0 (from huggingface_hub)\n","  Using cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.62.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.6.2)\n","Installing collected packages: fsspec, huggingface_hub\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2022.2.0\n","    Uninstalling fsspec-2022.2.0:\n","      Successfully uninstalled fsspec-2022.2.0\n","  Attempting uninstall: huggingface_hub\n","    Found existing installation: huggingface-hub 0.17.3\n","    Uninstalling huggingface-hub-0.17.3:\n","      Successfully uninstalled huggingface-hub-0.17.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2024.6.0 which is incompatible.\n","parlai 1.7.2 requires fsspec~=2022.2.0, but you have fsspec 2024.6.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fsspec-2024.6.0 huggingface_hub-0.23.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"KtVz5dCUmFkN"},"source":["# Chatting with a model\n","\n","Let's start by chatting interactively with a model file from our model zoo! We'll pick our \"tutorial transformer generator\" model, which is a generative transformer trained on pushshift.io Reddit. You can take a look at the [model zoo](https://parl.ai/docs/zoo.html) for a more complete list."]},{"cell_type":"code","source":["!parlai train_model -m ir_baseline -t personachat --dict-file /tmp/personachat.dict -ttim 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87-VsKTwZKVu","executionInfo":{"status":"ok","timestamp":1717607799879,"user_tz":420,"elapsed":57762,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}},"outputId":"73ea69f2-de39-4851-b117-6eadc0d8b243"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["17:15:52 | building dictionary first...\n","17:15:52 | Opt:\n","17:15:52 |     aggregate_micro: False\n","17:15:52 |     allow_missing_init_opts: False\n","17:15:52 |     batchsize: 1\n","17:15:52 |     bpe_add_prefix_space: None\n","17:15:52 |     bpe_debug: False\n","17:15:52 |     bpe_dropout: None\n","17:15:52 |     bpe_merge: None\n","17:15:52 |     bpe_vocab: None\n","17:15:52 |     clearml_log: False\n","17:15:52 |     clearml_project_name: ParlAI\n","17:15:52 |     clearml_task_name: 'Default Task'\n","17:15:52 |     datapath: /usr/local/lib/python3.10/dist-packages/data\n","17:15:52 |     datatype: train\n","17:15:52 |     dict_class: parlai.core.dict:DictionaryAgent\n","17:15:52 |     dict_endtoken: __end__\n","17:15:52 |     dict_file: /tmp/personachat.dict\n","17:15:52 |     dict_include_test: False\n","17:15:52 |     dict_include_valid: False\n","17:15:52 |     dict_initpath: None\n","17:15:52 |     dict_language: english\n","17:15:52 |     dict_loaded: False\n","17:15:52 |     dict_lower: False\n","17:15:52 |     dict_max_ngram_size: -1\n","17:15:52 |     dict_maxexs: -1\n","17:15:52 |     dict_maxtokens: -1\n","17:15:52 |     dict_minfreq: 0\n","17:15:52 |     dict_nulltoken: __null__\n","17:15:52 |     dict_starttoken: __start__\n","17:15:52 |     dict_textfields: text,labels\n","17:15:52 |     dict_tokenizer: re\n","17:15:52 |     dict_unktoken: __unk__\n","17:15:52 |     display_examples: False\n","17:15:52 |     download_path: None\n","17:15:52 |     dynamic_batching: None\n","17:15:52 |     eval_batchsize: None\n","17:15:52 |     eval_dynamic_batching: None\n","17:15:52 |     evaltask: None\n","17:15:52 |     final_extra_opt: \n","17:15:52 |     hide_labels: False\n","17:15:52 |     history_size: 1\n","17:15:52 |     image_cropsize: 224\n","17:15:52 |     image_mode: no_image_model\n","17:15:52 |     image_size: 256\n","17:15:52 |     init_model: None\n","17:15:52 |     init_opt: None\n","17:15:52 |     is_debug: False\n","17:15:52 |     label_candidates_file: None\n","17:15:52 |     length_penalty: 0.5\n","17:15:52 |     load_from_checkpoint: True\n","17:15:52 |     log_every_n_secs: -1\n","17:15:52 |     log_every_n_steps: 50\n","17:15:52 |     log_keep_fields: all\n","17:15:52 |     loglevel: info\n","17:15:52 |     max_train_steps: -1\n","17:15:52 |     max_train_time: 5.0\n","17:15:52 |     metrics: default\n","17:15:52 |     model: ir_baseline\n","17:15:52 |     model_file: None\n","17:15:52 |     multitask_weights: [1]\n","17:15:52 |     mutators: None\n","17:15:52 |     num_epochs: -1\n","17:15:52 |     num_workers: 0\n","17:15:52 |     override: \"{'model': 'ir_baseline', 'task': 'personachat', 'dict_file': '/tmp/personachat.dict', 'max_train_time': 5.0}\"\n","17:15:52 |     parlai_home: /usr/local/lib/python3.10/dist-packages\n","17:15:52 |     save_after_valid: False\n","17:15:52 |     save_every_n_secs: -1\n","17:15:52 |     save_format: conversations\n","17:15:52 |     seed: None\n","17:15:52 |     short_final_eval: False\n","17:15:52 |     starttime: Jun05_17-15\n","17:15:52 |     task: personachat\n","17:15:52 |     teacher_seed: None\n","17:15:52 |     tensorboard_log: False\n","17:15:52 |     tensorboard_logdir: None\n","17:15:52 |     validation_cutoff: 1.0\n","17:15:52 |     validation_every_n_epochs: -1\n","17:15:52 |     validation_every_n_secs: -1\n","17:15:52 |     validation_every_n_steps: -1\n","17:15:52 |     validation_max_exs: -1\n","17:15:52 |     validation_metric: accuracy\n","17:15:52 |     validation_metric_mode: None\n","17:15:52 |     validation_patience: 10\n","17:15:52 |     validation_share_agent: False\n","17:15:52 |     verbose: False\n","17:15:52 |     wandb_entity: None\n","17:15:52 |     wandb_log: False\n","17:15:52 |     wandb_log_model: False\n","17:15:52 |     wandb_name: None\n","17:15:52 |     wandb_project: None\n","17:15:52 |     world_logs: \n","17:15:52 | creating task(s): personachat\n","[building data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat]\n","17:15:52 | Downloading http://parl.ai/downloads/personachat/personachat.tgz to /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat.tgz\n","Downloading personachat.tgz: 100% 223M/223M [00:11<00:00, 19.6MB/s]\n","17:16:16 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n","Building dictionary:   0% 0.00/65.7k [00:00<?, ?ex/s]17:16:16 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n","Building dictionary: 100% 65.7k/65.7k [00:03<00:00, 19.2kex/s]\n","17:16:20 | Saving dictionary to /tmp/personachat.dict\n","17:16:20 | dictionary built with 18745 tokens in 0.0s\n","17:16:20 | loading dictionary from /tmp/personachat.dict\n","17:16:20 | num words = 18745\n","17:16:20 | Opt:\n","17:16:20 |     aggregate_micro: False\n","17:16:20 |     allow_missing_init_opts: False\n","17:16:20 |     batchsize: 1\n","17:16:20 |     bpe_add_prefix_space: None\n","17:16:20 |     bpe_debug: False\n","17:16:20 |     bpe_dropout: None\n","17:16:20 |     bpe_merge: None\n","17:16:20 |     bpe_vocab: None\n","17:16:20 |     clearml_log: False\n","17:16:20 |     clearml_project_name: ParlAI\n","17:16:20 |     clearml_task_name: 'Default Task'\n","17:16:20 |     datapath: /usr/local/lib/python3.10/dist-packages/data\n","17:16:20 |     datatype: train\n","17:16:20 |     dict_class: parlai.core.dict:DictionaryAgent\n","17:16:20 |     dict_endtoken: __end__\n","17:16:20 |     dict_file: /tmp/personachat.dict\n","17:16:20 |     dict_include_test: False\n","17:16:20 |     dict_include_valid: False\n","17:16:20 |     dict_initpath: None\n","17:16:20 |     dict_language: english\n","17:16:20 |     dict_loaded: True\n","17:16:20 |     dict_lower: False\n","17:16:20 |     dict_max_ngram_size: -1\n","17:16:20 |     dict_maxexs: -1\n","17:16:20 |     dict_maxtokens: -1\n","17:16:20 |     dict_minfreq: 0\n","17:16:20 |     dict_nulltoken: __null__\n","17:16:20 |     dict_starttoken: __start__\n","17:16:20 |     dict_textfields: text,labels\n","17:16:20 |     dict_tokenizer: re\n","17:16:20 |     dict_unktoken: __unk__\n","17:16:20 |     display_examples: False\n","17:16:20 |     download_path: None\n","17:16:20 |     dynamic_batching: None\n","17:16:20 |     eval_batchsize: None\n","17:16:20 |     eval_dynamic_batching: None\n","17:16:20 |     evaltask: None\n","17:16:20 |     final_extra_opt: \n","17:16:20 |     hide_labels: False\n","17:16:20 |     history_size: 1\n","17:16:20 |     image_cropsize: 224\n","17:16:20 |     image_mode: raw\n","17:16:20 |     image_size: 256\n","17:16:20 |     init_model: None\n","17:16:20 |     init_opt: None\n","17:16:20 |     is_debug: False\n","17:16:20 |     label_candidates_file: None\n","17:16:20 |     length_penalty: 0.5\n","17:16:20 |     load_from_checkpoint: True\n","17:16:20 |     log_every_n_secs: -1\n","17:16:20 |     log_every_n_steps: 50\n","17:16:20 |     log_keep_fields: all\n","17:16:20 |     loglevel: info\n","17:16:20 |     max_train_steps: -1\n","17:16:20 |     max_train_time: 5.0\n","17:16:20 |     metrics: default\n","17:16:20 |     model: ir_baseline\n","17:16:20 |     model_file: None\n","17:16:20 |     multitask_weights: [1]\n","17:16:20 |     mutators: None\n","17:16:20 |     num_epochs: -1\n","17:16:20 |     num_workers: 0\n","17:16:20 |     override: \"{'model': 'ir_baseline', 'task': 'personachat', 'dict_file': '/tmp/personachat.dict', 'max_train_time': 5.0}\"\n","17:16:20 |     parlai_home: /usr/local/lib/python3.10/dist-packages\n","17:16:20 |     save_after_valid: False\n","17:16:20 |     save_every_n_secs: -1\n","17:16:20 |     save_format: conversations\n","17:16:20 |     seed: None\n","17:16:20 |     short_final_eval: False\n","17:16:20 |     starttime: Jun05_17-15\n","17:16:20 |     task: personachat\n","17:16:20 |     teacher_seed: None\n","17:16:20 |     tensorboard_log: False\n","17:16:20 |     tensorboard_logdir: None\n","17:16:20 |     validation_cutoff: 1.0\n","17:16:20 |     validation_every_n_epochs: -1\n","17:16:20 |     validation_every_n_secs: -1\n","17:16:20 |     validation_every_n_steps: -1\n","17:16:20 |     validation_max_exs: -1\n","17:16:20 |     validation_metric: accuracy\n","17:16:20 |     validation_metric_mode: None\n","17:16:20 |     validation_patience: 10\n","17:16:20 |     validation_share_agent: False\n","17:16:20 |     verbose: False\n","17:16:20 |     wandb_entity: None\n","17:16:20 |     wandb_log: False\n","17:16:20 |     wandb_log_model: False\n","17:16:20 |     wandb_name: None\n","17:16:20 |     wandb_project: None\n","17:16:20 |     world_logs: \n","17:16:20 | creating task(s): personachat\n","17:16:20 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n","17:16:22 | training...\n","17:16:22 | time:0s total_exs:50 total_steps:50 epochs:0.00\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1600   50 .2907   .1800    .6200         1   .4000      .2979   .2963\n","\n","17:16:22 | time:1s total_exs:100 total_steps:100 epochs:0.00\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2746   .1600    .7200         1   .4200      .2804   .2855\n","\n","17:16:22 | time:1s total_exs:150 total_steps:150 epochs:0.00\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1400   50 .2362   .1400    .6800         1   .4800      .2353   .2460\n","\n","17:16:22 | time:1s total_exs:200 total_steps:200 epochs:0.00\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2844   .2000    .6800         1   .5000      .2847   .2967\n","\n","17:16:22 | time:1s total_exs:250 total_steps:250 epochs:0.00\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3086   .2400    .7000         1   .5000      .3130   .3125\n","\n","17:16:22 | time:1s total_exs:300 total_steps:300 epochs:0.00\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2946   .2000    .5800         1   .3200      .2906   .3076\n","\n","17:16:23 | time:1s total_exs:350 total_steps:350 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2596   .1800    .5800         1   .4400      .2557   .2728\n","\n","17:16:23 | time:1s total_exs:400 total_steps:400 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2439   50 .3318   .2400    .7000         1   .4800      .3266   .3464\n","\n","17:16:23 | time:1s total_exs:450 total_steps:450 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1692   50 .2475   .1600    .6000         1   .4600      .2508   .2572\n","\n","17:16:23 | time:1s total_exs:500 total_steps:500 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2442   .1600    .6600         1   .5200      .2425   .2555\n","\n","17:16:23 | time:1s total_exs:550 total_steps:550 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3174   .2200    .5600         1   .4200      .3213   .3247\n","\n","17:16:23 | time:1s total_exs:600 total_steps:600 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3790   .2800    .6600         1   .5000      .3755   .3977\n","\n","17:16:23 | time:1s total_exs:650 total_steps:650 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1000   .1000   50 .2093   .1000    .7400         1   .4600      .2121   .2146\n","\n","17:16:23 | time:1s total_exs:700 total_steps:700 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3074   .2200    .7800         1   .5200      .3157   .3131\n","\n","17:16:23 | time:1s total_exs:750 total_steps:750 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2600   .2600   50 .3621   .2600    .6800         1   .5200      .3678   .3708\n","\n","17:16:23 | time:2s total_exs:800 total_steps:800 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3601   .2800    .5800         1   .4000      .3571   .3742\n","\n","17:16:23 | time:2s total_exs:850 total_steps:850 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2473   .1600    .5800         1   .4200      .2480   .2551\n","\n","17:16:23 | time:2s total_exs:900 total_steps:900 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2814   .1600    .6400         1   .4400      .2734   .3019\n","\n","17:16:23 | time:2s total_exs:950 total_steps:950 epochs:0.01\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2940   .2000    .6800         1   .4200      .2882   .3106\n","\n","17:16:23 | time:2s total_exs:1000 total_steps:1000 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1458   50 .2343   .1400    .6800         1   .4000      .2395   .2396\n","\n","17:16:23 | time:2s total_exs:1050 total_steps:1050 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .2984   .2400    .5400         1   .3800      .3020   .3030\n","\n","17:16:23 | time:2s total_exs:1100 total_steps:1100 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1400   50 .2237   .1400    .5000         1   .3400      .2240   .2284\n","\n","17:16:23 | time:2s total_exs:1150 total_steps:1150 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3142   .2200    .6000         1   .4200      .3108   .3414\n","\n","17:16:24 | time:2s total_exs:1200 total_steps:1200 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3452   .2400    .7800         1   .5600      .3425   .3558\n","\n","17:16:24 | time:2s total_exs:1250 total_steps:1250 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3618   .2800    .6600         1   .5200      .3572   .3792\n","\n","17:16:24 | time:2s total_exs:1300 total_steps:1300 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3366   .2400    .8000         1   .4800      .3304   .3508\n","\n","17:16:24 | time:2s total_exs:1350 total_steps:1350 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2568   .1600    .6000         1   .4600      .2651   .2609\n","\n","17:16:24 | time:2s total_exs:1400 total_steps:1400 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2492   .1800    .6600         1   .4400      .2429   .2803\n","\n","17:16:24 | time:2s total_exs:1450 total_steps:1450 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1200   .1200   50 .1748   .1200    .6200         1   .4000      .1745   .1827\n","\n","17:16:24 | time:2s total_exs:1500 total_steps:1500 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2763   .2000    .6200         1   .4400      .2761   .2847\n","\n","17:16:24 | time:2s total_exs:1550 total_steps:1550 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3128   .2400    .6600         1   .4000      .3170   .3160\n","\n","17:16:24 | time:2s total_exs:1600 total_steps:1600 epochs:0.02\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3383   .2200    .6400         1   .4600      .3370   .3499\n","\n","17:16:24 | time:2s total_exs:1650 total_steps:1650 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .3200   .3200   50 .4015   .3200    .8000         1   .5400      .4015   .4105\n","\n","17:16:24 | time:2s total_exs:1700 total_steps:1700 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .3000   .3000   50 .3677   .3000    .6200         1   .4800      .3662   .3754\n","\n","17:16:24 | time:2s total_exs:1750 total_steps:1750 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2586   .1600    .5400         1   .4000      .2572   .2694\n","\n","17:16:24 | time:2s total_exs:1800 total_steps:1800 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3130   .2400    .6800         1   .5000      .3190   .3122\n","\n","17:16:24 | time:2s total_exs:1850 total_steps:1850 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1200   .1200   50 .2056   .1200    .5400         1   .3800      .1982   .2247\n","\n","17:16:24 | time:2s total_exs:1900 total_steps:1900 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3276   .2400    .7400         1   .5600      .3239   .3404\n","\n","17:16:24 | time:3s total_exs:1950 total_steps:1950 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .3000   .3000   50 .3812   .3000    .6800         1   .5200      .3821   .3864\n","\n","17:16:24 | time:3s total_exs:2000 total_steps:2000 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2841   .2000    .6200         1   .4400      .2796   .2953\n","\n","17:16:24 | time:3s total_exs:2050 total_steps:2050 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2519   .1600    .5800         1   .3600      .2646   .2506\n","\n","17:16:24 | time:3s total_exs:2100 total_steps:2100 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3604   .2800    .6400         1   .5600      .3562   .3758\n","\n","17:16:24 | time:3s total_exs:2150 total_steps:2150 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2431   .1600    .5600         1   .4000      .2382   .2540\n","\n","17:16:24 | time:3s total_exs:2200 total_steps:2200 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2957   .2000    .6800         1   .5200      .2955   .3038\n","\n","17:16:24 | time:3s total_exs:2250 total_steps:2250 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1630   50 .2642   .1600    .6800         1   .5000      .2692   .2724\n","\n","17:16:24 | time:3s total_exs:2300 total_steps:2300 epochs:0.03\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3576   .2400    .6800         1   .5400      .3577   .3732\n","\n","17:16:25 | time:3s total_exs:2350 total_steps:2350 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3123   .2200    .5600         1   .4000      .3105   .3236\n","\n","17:16:25 | time:3s total_exs:2400 total_steps:2400 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3181   .2200    .6200         1   .3600      .3207   .3218\n","\n","17:16:25 | time:3s total_exs:2450 total_steps:2450 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3197   .2400    .7200         1   .4800      .3231   .3233\n","\n","17:16:25 | time:3s total_exs:2500 total_steps:2500 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2471   .1600    .6000         1   .4000      .2407   .2595\n","\n","17:16:25 | time:3s total_exs:2550 total_steps:2550 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2700   .1800    .6800         1   .4800      .2685   .2808\n","\n","17:16:25 | time:3s total_exs:2600 total_steps:2600 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3708   .2800    .7800         1   .6400      .3728   .3762\n","\n","17:16:25 | time:3s total_exs:2650 total_steps:2650 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3553   .2800    .6800         1   .5200      .3600   .3587\n","\n","17:16:25 | time:3s total_exs:2700 total_steps:2700 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2882   50 .3685   .2800    .6200         1   .4200      .3651   .3867\n","\n","17:16:25 | time:3s total_exs:2750 total_steps:2750 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .2981   .2200    .6200         1   .3800      .2986   .3019\n","\n","17:16:25 | time:3s total_exs:2800 total_steps:2800 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2703   .1800    .6200         1   .4600      .2775   .2707\n","\n","17:16:25 | time:3s total_exs:2850 total_steps:2850 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3505   .2800    .6600         1   .4600      .3508   .3570\n","\n","17:16:25 | time:3s total_exs:2900 total_steps:2900 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3637   .2800    .6400         1   .5600      .3577   .3798\n","\n","17:16:25 | time:3s total_exs:2950 total_steps:2950 epochs:0.04\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1400   50 .2557   .1400    .7200         1   .4800      .2560   .2690\n","\n","17:16:25 | time:3s total_exs:3000 total_steps:3000 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3423   .2800    .7600         1   .5800      .3458   .3442\n","\n","17:16:25 | time:3s total_exs:3050 total_steps:3050 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2830   .2000    .7600         1   .5200      .2954   .2804\n","\n","17:16:25 | time:4s total_exs:3100 total_steps:3100 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2600   .2600   50 .3461   .2600    .7600         1   .5600      .3509   .3520\n","\n","17:16:25 | time:4s total_exs:3150 total_steps:3150 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2535   .1600    .7200         1   .4400      .2632   .2542\n","\n","17:16:25 | time:4s total_exs:3200 total_steps:3200 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2600   .2600   50 .3405   .2600    .7200         1   .5400      .3390   .3499\n","\n","17:16:25 | time:4s total_exs:3250 total_steps:3250 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .3000   .3000   50 .3900   .3000    .6600         1   .4400      .3867   .4061\n","\n","17:16:25 | time:4s total_exs:3300 total_steps:3300 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2397   .1600    .6400         1   .4000      .2353   .2542\n","\n","17:16:25 | time:4s total_exs:3350 total_steps:3350 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1200   .1200   50 .2256   .1200    .6800         1   .4200      .2298   .2409\n","\n","17:16:25 | time:4s total_exs:3400 total_steps:3400 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2985   .1800    .6000         1   .4800      .3031   .3076\n","\n","17:16:25 | time:4s total_exs:3450 total_steps:3450 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .0600   .0600   50 .1371   .0600    .5000         1   .2600      .1314   .1515\n","\n","17:16:26 | time:4s total_exs:3500 total_steps:3500 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2721   .1800    .5800         1   .4800      .2788   .2767\n","\n","17:16:26 | time:4s total_exs:3550 total_steps:3550 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2793   .1800    .7200         1   .4200      .2873   .2802\n","\n","17:16:26 | time:4s total_exs:3600 total_steps:3600 epochs:0.05\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2600   .2600   50 .3476   .2600    .7400         1   .5200      .3461   .3548\n","\n","17:16:26 | time:4s total_exs:3650 total_steps:3650 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2800   .2800   50 .3541   .2800    .6200         1   .4800      .3541   .3598\n","\n","17:16:26 | time:4s total_exs:3700 total_steps:3700 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3064   .2200    .6600         1   .4200      .3114   .3103\n","\n","17:16:26 | time:4s total_exs:3750 total_steps:3750 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2667   .1800    .6600         1   .4400      .2699   .2723\n","\n","17:16:26 | time:4s total_exs:3800 total_steps:3800 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2454   .1600    .6000         1   .4600      .2467   .2540\n","\n","17:16:26 | time:4s total_exs:3850 total_steps:3850 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2038   50 .2683   .2000    .5400         1   .3800      .2693   .2772\n","\n","17:16:26 | time:4s total_exs:3900 total_steps:3900 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3346   .2400    .8400         1   .6200      .3366   .3438\n","\n","17:16:26 | time:4s total_exs:3950 total_steps:3950 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1200   .1200   50 .2030   .1200    .4600         1   .3000      .1962   .2199\n","\n","17:16:26 | time:4s total_exs:4000 total_steps:4000 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .3200   .3200   50 .3937   .3200    .6400         1   .4600      .4012   .3902\n","\n","17:16:26 | time:4s total_exs:4050 total_steps:4050 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1400   50 .2365   .1400    .5400         1   .4400      .2355   .2447\n","\n","17:16:26 | time:4s total_exs:4100 total_steps:4100 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2600   .2600   50 .3518   .2600    .7800         1   .5400      .3576   .3544\n","\n","17:16:26 | time:4s total_exs:4150 total_steps:4150 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2624   .1800    .5800         1   .4000      .2689   .2721\n","\n","17:16:26 | time:4s total_exs:4200 total_steps:4200 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1838   50 .3025   .1800    .5800         1   .3400      .3099   .3026\n","\n","17:16:26 | time:5s total_exs:4250 total_steps:4250 epochs:0.06\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2560   .1800    .5600         1   .3600      .2505   .2721\n","\n","17:16:26 | time:5s total_exs:4300 total_steps:4300 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2693   .1600    .5800         1   .4600      .2631   .2898\n","\n","17:16:26 | time:5s total_exs:4350 total_steps:4350 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .3000   .3000   50 .3716   .3000    .7000         1   .4800      .3782   .3741\n","\n","17:16:26 | time:5s total_exs:4400 total_steps:4400 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1800   .1800   50 .2781   .1800    .6400         1   .3200      .2738   .2915\n","\n","17:16:26 | time:5s total_exs:4450 total_steps:4450 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2000   .2000   50 .2900   .2000    .6800         1   .6000      .2930   .2957\n","\n","17:16:26 | time:5s total_exs:4500 total_steps:4500 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1600   .1600   50 .2623   .1600    .5800         1   .4600      .2579   .2760\n","\n","17:16:26 | time:5s total_exs:4550 total_steps:4550 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2200   .2200   50 .3177   .2200    .7200         1   .5000      .3329   .3121\n","\n","17:16:26 | time:5s total_exs:4600 total_steps:4600 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2400   .2400   50 .3530   .2400    .7400         1   .5200      .3639   .3565\n","\n","17:16:27 | time:5s total_exs:4650 total_steps:4650 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1400   50 .2668   .1400    .5600         1   .4000      .2632   .2869\n","\n","17:16:27 | time:5s total_exs:4700 total_steps:4700 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1200   .1200   50 .2201   .1200    .5000         1   .3400      .2130   .2412\n","\n","17:16:27 | time:5s total_exs:4750 total_steps:4750 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .3000   .3000   50 .3763   .3000    .6600         1   .5000      .3762   .3857\n","\n","17:16:27 | time:5s total_exs:4800 total_steps:4800 epochs:0.07\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1400   50 .2288   .1400    .6000         1   .4000      .2308   .2372\n","\n","17:16:27 | max_train_time elapsed:5.000820875167847s\n","17:16:27 | creating task(s): personachat\n","17:16:27 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/valid_self_original.txt\n","17:16:27 | running eval: valid\n","17:16:31 | eval completed in 4.70s\n","17:16:31 | \u001b[1mvalid:\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2223   .2225 7801 .3083   .2223    .6667         1   .4711      .3086   .3168\n","\u001b[0m\n","17:16:31 | creating task(s): personachat\n","17:16:31 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/test_self_original.txt\n","17:16:32 | running eval: test\n","17:16:38 | eval completed in 6.04s\n","17:16:38 | \u001b[1mtest:\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .2114   .2117 7512 .3018   .2114    .6665         1   .4601      .3028   .3102\n","\u001b[0m\n"]}]},{"cell_type":"code","source":["!parlai train_model -m starspace -t personachat --dict-file /tmp/personachat.dict -ttim 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qjxsj5Jwf0zJ","executionInfo":{"status":"ok","timestamp":1717610196293,"user_tz":420,"elapsed":50306,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}},"outputId":"a063e727-8e7a-40ef-824d-a7e27f99f0d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["17:55:51 | building dictionary first...\n","17:55:51 | creating StarspaceAgent\n","17:55:51 | loading dictionary from /tmp/personachat.dict\n","17:55:51 | num words = 18745\n","/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n","17:55:51 | Opt:\n","17:55:51 |     aggregate_micro: False\n","17:55:51 |     allow_missing_init_opts: False\n","17:55:51 |     batchsize: 1\n","17:55:51 |     bpe_add_prefix_space: None\n","17:55:51 |     bpe_debug: False\n","17:55:51 |     bpe_dropout: None\n","17:55:51 |     bpe_merge: None\n","17:55:51 |     bpe_vocab: None\n","17:55:51 |     cache_size: 1000\n","17:55:51 |     clearml_log: False\n","17:55:51 |     clearml_project_name: ParlAI\n","17:55:51 |     clearml_task_name: 'Default Task'\n","17:55:51 |     datapath: /usr/local/lib/python3.10/dist-packages/data\n","17:55:51 |     datatype: train\n","17:55:51 |     dict_class: parlai.core.dict:DictionaryAgent\n","17:55:51 |     dict_endtoken: __end__\n","17:55:51 |     dict_file: /tmp/personachat.dict\n","17:55:51 |     dict_include_test: False\n","17:55:51 |     dict_include_valid: False\n","17:55:51 |     dict_initpath: None\n","17:55:51 |     dict_language: english\n","17:55:51 |     dict_loaded: True\n","17:55:51 |     dict_lower: False\n","17:55:51 |     dict_max_ngram_size: -1\n","17:55:51 |     dict_maxexs: -1\n","17:55:51 |     dict_maxtokens: -1\n","17:55:51 |     dict_minfreq: 0\n","17:55:51 |     dict_nulltoken: __null__\n","17:55:51 |     dict_starttoken: __start__\n","17:55:51 |     dict_textfields: text,labels\n","17:55:51 |     dict_tokenizer: re\n","17:55:51 |     dict_unktoken: __unk__\n","17:55:51 |     display_examples: False\n","17:55:51 |     download_path: None\n","17:55:51 |     dynamic_batching: None\n","17:55:51 |     embedding_type: random\n","17:55:51 |     embeddingnorm: 10\n","17:55:51 |     embeddingsize: 128\n","17:55:51 |     eval_batchsize: None\n","17:55:51 |     eval_dynamic_batching: None\n","17:55:51 |     evaltask: None\n","17:55:51 |     final_extra_opt: \n","17:55:51 |     fixed_candidates_file: None\n","17:55:51 |     hide_labels: False\n","17:55:51 |     history_length: 10000\n","17:55:51 |     history_replies: label_else_model\n","17:55:51 |     image_cropsize: 224\n","17:55:51 |     image_mode: raw\n","17:55:51 |     image_size: 256\n","17:55:51 |     init_model: None\n","17:55:51 |     init_opt: None\n","17:55:51 |     input_dropout: 0\n","17:55:51 |     is_debug: False\n","17:55:51 |     learningrate: 0.1\n","17:55:51 |     lins: 0\n","17:55:51 |     load_from_checkpoint: True\n","17:55:51 |     log_every_n_secs: -1\n","17:55:51 |     log_every_n_steps: 50\n","17:55:51 |     log_keep_fields: all\n","17:55:51 |     loglevel: info\n","17:55:51 |     margin: 0.1\n","17:55:51 |     max_train_steps: -1\n","17:55:51 |     max_train_time: 5.0\n","17:55:51 |     metrics: default\n","17:55:51 |     model: starspace\n","17:55:51 |     model_file: None\n","17:55:51 |     multitask_weights: [1]\n","17:55:51 |     mutators: None\n","17:55:51 |     neg_samples: 10\n","17:55:51 |     num_epochs: -1\n","17:55:51 |     num_workers: 0\n","17:55:51 |     optimizer: sgd\n","17:55:51 |     override: \"{'model': 'starspace', 'task': 'personachat', 'dict_file': '/tmp/personachat.dict', 'max_train_time': 5.0}\"\n","17:55:51 |     parlai_home: /usr/local/lib/python3.10/dist-packages\n","17:55:51 |     parrot_neg: 0\n","17:55:51 |     save_after_valid: False\n","17:55:51 |     save_every_n_secs: -1\n","17:55:51 |     save_format: conversations\n","17:55:51 |     seed: None\n","17:55:51 |     share_embeddings: True\n","17:55:51 |     short_final_eval: False\n","17:55:51 |     starttime: Jun05_17-55\n","17:55:51 |     task: personachat\n","17:55:51 |     teacher_seed: None\n","17:55:51 |     tensorboard_log: False\n","17:55:51 |     tensorboard_logdir: None\n","17:55:51 |     tfidf: False\n","17:55:51 |     truncate: -1\n","17:55:51 |     validation_cutoff: 1.0\n","17:55:51 |     validation_every_n_epochs: -1\n","17:55:51 |     validation_every_n_secs: -1\n","17:55:51 |     validation_every_n_steps: -1\n","17:55:51 |     validation_max_exs: -1\n","17:55:51 |     validation_metric: accuracy\n","17:55:51 |     validation_metric_mode: None\n","17:55:51 |     validation_patience: 10\n","17:55:51 |     validation_share_agent: False\n","17:55:51 |     verbose: False\n","17:55:51 |     wandb_entity: None\n","17:55:51 |     wandb_log: False\n","17:55:51 |     wandb_log_model: False\n","17:55:51 |     wandb_name: None\n","17:55:51 |     wandb_project: None\n","17:55:51 |     world_logs: \n","17:55:51 | creating task(s): personachat\n","17:55:51 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n","17:55:53 | training...\n","17:55:53 | \u001b[33mMetric mean_rank is assumed to be averaged per example.\u001b[0m\n","17:55:53 | \u001b[33mMetric loss is assumed to be averaged per example.\u001b[0m\n","17:55:53 | time:0s total_exs:50 total_steps:50 epochs:0.00\n","    exs  loss  mean_rank\n","     50 2.837      5.396\n","\n","17:55:54 | time:1s total_exs:100 total_steps:100 epochs:0.00\n","    exs  loss  mean_rank\n","     50 1.873       4.12\n","\n","17:55:54 | time:1s total_exs:150 total_steps:150 epochs:0.00\n","    exs  loss  mean_rank\n","     50 1.604       3.52\n","\n","17:55:54 | time:1s total_exs:200 total_steps:200 epochs:0.00\n","    exs  loss  mean_rank\n","     50 1.414       3.02\n","\n","17:55:54 | time:1s total_exs:250 total_steps:250 epochs:0.00\n","    exs  loss  mean_rank\n","     50 1.296       3.66\n","\n","17:55:54 | time:1s total_exs:300 total_steps:300 epochs:0.00\n","    exs  loss  mean_rank\n","     50 1.283       3.68\n","\n","17:55:54 | time:1s total_exs:350 total_steps:350 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.192       3.08\n","\n","17:55:55 | time:2s total_exs:400 total_steps:400 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.157       3.66\n","\n","17:55:55 | time:2s total_exs:450 total_steps:450 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.186       3.76\n","\n","17:55:55 | time:2s total_exs:500 total_steps:500 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.172       3.92\n","\n","17:55:55 | time:2s total_exs:550 total_steps:550 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.122       3.82\n","\n","17:55:55 | time:2s total_exs:600 total_steps:600 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.088       3.26\n","\n","17:55:56 | time:3s total_exs:650 total_steps:650 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.071       2.82\n","\n","17:55:56 | time:3s total_exs:700 total_steps:700 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.076       3.02\n","\n","17:55:56 | time:3s total_exs:750 total_steps:750 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.109       3.82\n","\n","17:55:56 | time:3s total_exs:800 total_steps:800 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.077       2.88\n","\n","17:55:56 | time:3s total_exs:850 total_steps:850 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.134       4.32\n","\n","17:55:56 | time:3s total_exs:900 total_steps:900 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.108       3.88\n","\n","17:55:57 | time:4s total_exs:950 total_steps:950 epochs:0.01\n","    exs  loss  mean_rank\n","     50 1.123       4.22\n","\n","17:55:57 | time:4s total_exs:1000 total_steps:1000 epochs:0.02\n","    exs  loss  mean_rank\n","     50 1.073       3.22\n","\n","17:55:57 | time:4s total_exs:1050 total_steps:1050 epochs:0.02\n","    exs  loss  mean_rank\n","     50 1.088       3.84\n","\n","17:55:57 | time:4s total_exs:1100 total_steps:1100 epochs:0.02\n","    exs  loss  mean_rank\n","     50  1.08       4.02\n","\n","17:55:57 | time:4s total_exs:1150 total_steps:1150 epochs:0.02\n","    exs  loss  mean_rank\n","     50 1.096       3.64\n","\n","17:55:57 | time:4s total_exs:1200 total_steps:1200 epochs:0.02\n","    exs  loss  mean_rank\n","     50  1.05       3.62\n","\n","17:55:58 | time:5s total_exs:1250 total_steps:1250 epochs:0.02\n","    exs  loss  mean_rank\n","     50 1.042        3.4\n","\n","17:55:58 | time:5s total_exs:1300 total_steps:1300 epochs:0.02\n","    exs  loss  mean_rank\n","     50 1.043       3.06\n","\n","17:55:58 | time:5s total_exs:1350 total_steps:1350 epochs:0.02\n","    exs  loss  mean_rank\n","     50 1.054       3.14\n","\n","17:55:58 | max_train_time elapsed:5.00128698348999s\n","17:55:58 | creating task(s): personachat\n","17:55:58 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/valid_self_original.txt\n","17:55:58 | running eval: valid\n","17:56:16 | eval completed in 17.74s\n","17:56:16 | \u001b[1mvalid:\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1549   .1550 7801 .2358   .1549    .7066         1   .4598      .2412   .2386\n","\u001b[0m\n","17:56:16 | creating task(s): personachat\n","17:56:16 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/test_self_original.txt\n","17:56:16 | running eval: test\n","17:56:34 | eval completed in 18.33s\n","17:56:34 | \u001b[1mtest:\n","    accuracy  bleu-4  exs    f1  hits@1  hits@10  hits@100  hits@5  precision  recall\n","       .1400   .1404 7512 .2248   .1400    .6898         1   .4483      .2306   .2282\n","\u001b[0m\n"]}]},{"cell_type":"code","source":["!parlai train_model -m seq2seq -t personachat --dict-file /tmp/personachat.dict -ttim 5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7r2P36fUj1WQ","executionInfo":{"status":"ok","timestamp":1717610752943,"user_tz":420,"elapsed":312670,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}},"outputId":"9d6e1928-4b75-4acb-b6ec-0ff37b3617fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["18:00:46 | building dictionary first...\n","18:00:46 | Using CUDA\n","18:00:46 | loading dictionary from /tmp/personachat.dict\n","18:00:46 | num words = 18745\n","18:00:46 | Total parameters: 7,745,209 (7,745,209 trainable)\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n","18:00:46 | Opt:\n","18:00:46 |     adafactor_eps: '(1e-30, 0.001)'\n","18:00:46 |     adam_eps: 1e-08\n","18:00:46 |     add_p1_after_newln: False\n","18:00:46 |     aggregate_micro: False\n","18:00:46 |     allow_missing_init_opts: False\n","18:00:46 |     attention: none\n","18:00:46 |     attention_length: 48\n","18:00:46 |     attention_time: post\n","18:00:46 |     batchsize: 1\n","18:00:46 |     beam_block_full_context: True\n","18:00:46 |     beam_block_list_filename: None\n","18:00:46 |     beam_block_ngram: -1\n","18:00:46 |     beam_context_block_ngram: -1\n","18:00:46 |     beam_delay: 30\n","18:00:46 |     beam_length_penalty: 0.65\n","18:00:46 |     beam_min_length: 1\n","18:00:46 |     beam_size: 1\n","18:00:46 |     betas: '(0.9, 0.999)'\n","18:00:46 |     bidirectional: False\n","18:00:46 |     bpe_add_prefix_space: None\n","18:00:46 |     bpe_debug: False\n","18:00:46 |     bpe_dropout: None\n","18:00:46 |     bpe_merge: None\n","18:00:46 |     bpe_vocab: None\n","18:00:46 |     clearml_log: False\n","18:00:46 |     clearml_project_name: ParlAI\n","18:00:46 |     clearml_task_name: 'Default Task'\n","18:00:46 |     compute_tokenized_bleu: False\n","18:00:46 |     datapath: /usr/local/lib/python3.10/dist-packages/data\n","18:00:46 |     datatype: train\n","18:00:46 |     decoder: same\n","18:00:46 |     delimiter: '\\n'\n","18:00:46 |     dict_class: parlai.core.dict:DictionaryAgent\n","18:00:46 |     dict_endtoken: __end__\n","18:00:46 |     dict_file: /tmp/personachat.dict\n","18:00:46 |     dict_include_test: False\n","18:00:46 |     dict_include_valid: False\n","18:00:46 |     dict_initpath: None\n","18:00:46 |     dict_language: english\n","18:00:46 |     dict_loaded: True\n","18:00:46 |     dict_lower: False\n","18:00:46 |     dict_max_ngram_size: -1\n","18:00:46 |     dict_maxexs: -1\n","18:00:46 |     dict_maxtokens: -1\n","18:00:46 |     dict_minfreq: 0\n","18:00:46 |     dict_nulltoken: __null__\n","18:00:46 |     dict_starttoken: __start__\n","18:00:46 |     dict_textfields: text,labels\n","18:00:46 |     dict_tokenizer: re\n","18:00:46 |     dict_unktoken: __unk__\n","18:00:46 |     display_examples: False\n","18:00:46 |     download_path: None\n","18:00:46 |     dropout: 0.1\n","18:00:46 |     dynamic_batching: None\n","18:00:46 |     embedding_projection: random\n","18:00:46 |     embedding_type: random\n","18:00:46 |     embeddingsize: 128\n","18:00:46 |     eval_batchsize: None\n","18:00:46 |     eval_dynamic_batching: None\n","18:00:46 |     evaltask: None\n","18:00:46 |     final_extra_opt: \n","18:00:46 |     force_fp16_tokens: False\n","18:00:46 |     fp16: False\n","18:00:46 |     fp16_impl: safe\n","18:00:46 |     gpu: -1\n","18:00:46 |     gpu_beam_blocking: False\n","18:00:46 |     gradient_clip: 0.1\n","18:00:46 |     hiddensize: 128\n","18:00:46 |     hide_labels: False\n","18:00:46 |     history_add_global_end_token: None\n","18:00:46 |     history_reversed: False\n","18:00:46 |     history_size: -1\n","18:00:46 |     image_cropsize: 224\n","18:00:46 |     image_mode: raw\n","18:00:46 |     image_size: 256\n","18:00:46 |     inference: greedy\n","18:00:46 |     init_model: None\n","18:00:46 |     init_opt: None\n","18:00:46 |     input_dropout: 0.0\n","18:00:46 |     interactive_mode: False\n","18:00:46 |     invsqrt_lr_decay_gamma: -1\n","18:00:46 |     is_debug: False\n","18:00:46 |     label_truncate: None\n","18:00:46 |     lambda_decay: 0.9\n","18:00:46 |     learningrate: 1\n","18:00:46 |     load_from_checkpoint: True\n","18:00:46 |     log_every_n_secs: -1\n","18:00:46 |     log_every_n_steps: 50\n","18:00:46 |     log_keep_fields: all\n","18:00:46 |     loglevel: info\n","18:00:46 |     lookuptable: unique\n","18:00:46 |     lr_scheduler: reduceonplateau\n","18:00:46 |     lr_scheduler_decay: 0.5\n","18:00:46 |     lr_scheduler_patience: 3\n","18:00:46 |     max_train_steps: -1\n","18:00:46 |     max_train_time: 5.0\n","18:00:46 |     metrics: default\n","18:00:46 |     model: seq2seq\n","18:00:46 |     model_file: None\n","18:00:46 |     momentum: 0\n","18:00:46 |     multitask_weights: [1]\n","18:00:46 |     mutators: None\n","18:00:46 |     nesterov: True\n","18:00:46 |     no_cuda: False\n","18:00:46 |     num_epochs: -1\n","18:00:46 |     num_workers: 0\n","18:00:46 |     numlayers: 2\n","18:00:46 |     numsoftmax: 1\n","18:00:46 |     nus: (0.7,)\n","18:00:46 |     omega_bound: 0.3\n","18:00:46 |     optimizer: sgd\n","18:00:46 |     override: \"{'model': 'seq2seq', 'task': 'personachat', 'dict_file': '/tmp/personachat.dict', 'max_train_time': 5.0}\"\n","18:00:46 |     p_reset: True\n","18:00:46 |     parlai_home: /usr/local/lib/python3.10/dist-packages\n","18:00:46 |     person_tokens: False\n","18:00:46 |     rank_candidates: False\n","18:00:46 |     rnn_class: lstm\n","18:00:46 |     save_after_valid: False\n","18:00:46 |     save_every_n_secs: -1\n","18:00:46 |     save_format: conversations\n","18:00:46 |     seed: None\n","18:00:46 |     short_final_eval: False\n","18:00:46 |     skip_generation: False\n","18:00:46 |     special_tok_lst: None\n","18:00:46 |     split_lines: False\n","18:00:46 |     starttime: Jun05_18-00\n","18:00:46 |     task: personachat\n","18:00:46 |     teacher_seed: None\n","18:00:46 |     temperature: 1.0\n","18:00:46 |     tensorboard_log: False\n","18:00:46 |     tensorboard_logdir: None\n","18:00:46 |     text_truncate: None\n","18:00:46 |     topk: 10\n","18:00:46 |     topp: 0.9\n","18:00:46 |     truncate: -1\n","18:00:46 |     update_freq: 1\n","18:00:46 |     use_reply: label\n","18:00:46 |     validation_cutoff: 1.0\n","18:00:46 |     validation_every_n_epochs: -1\n","18:00:46 |     validation_every_n_secs: -1\n","18:00:46 |     validation_every_n_steps: -1\n","18:00:46 |     validation_max_exs: -1\n","18:00:46 |     validation_metric: accuracy\n","18:00:46 |     validation_metric_mode: None\n","18:00:46 |     validation_patience: 10\n","18:00:46 |     validation_share_agent: False\n","18:00:46 |     verbose: False\n","18:00:46 |     verbose_topk: -1\n","18:00:46 |     wandb_entity: None\n","18:00:46 |     wandb_log: False\n","18:00:46 |     wandb_log_model: False\n","18:00:46 |     wandb_name: None\n","18:00:46 |     wandb_project: None\n","18:00:46 |     warmup_rate: 0.0001\n","18:00:46 |     warmup_updates: -1\n","18:00:46 |     weight_decay: None\n","18:00:46 |     world_logs: \n","18:00:46 | creating task(s): personachat\n","18:00:46 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/train_self_original.txt\n","18:00:48 | training...\n","18:00:50 | time:2s total_exs:50 total_steps:50 epochs:0.00\n","    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  \\\n","   151.2     1 151.2  3707       0          0 24.52   50  4.099   .00568  12.8  9.42   1  12.8   \n","    ltps  ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  tpb  tps   ups  \n","   313.9       0          0 12335     .04688         0                   50  164 4021 24.53\n","\n","18:00:52 | time:4s total_exs:100 total_steps:100 epochs:0.00\n","    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  \\\n","   153.2     1 153.2  5971       0          0 38.97   50  3.932  .005675 13.86 8.963   1 13.86   \n","    ltps  ltrunc  ltrunclen  ppl  token_acc  token_em  total_train_updates   tpb  tps   ups  \n","   540.2       0          0 7807     .08514         0                  100 167.1 6512 38.99\n","\n","18:00:53 | time:5s total_exs:150 total_steps:150 epochs:0.00\n","    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  \\\n","   146.3     1 146.3  5767       0          0 39.41   50  3.955  .005673 13.58 8.754   1 13.58   \n","    ltps  ltrunc  ltrunclen  ppl  token_acc  token_em  total_train_updates   tpb  tps   ups  \n","   535.2       0          0 6333      .1281         0                  150 159.9 6302 39.42\n","\n","18:00:53 | max_train_time elapsed:5.007378339767456s\n","18:00:53 | creating task(s): personachat\n","18:00:53 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/valid_self_original.txt\n","18:00:53 | running eval: valid\n","18:03:25 | eval completed in 151.48s\n","18:03:25 | \u001b[1mvalid:\n","    accuracy    bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gen_n_toks  gpu_mem  \\\n","           0 2.289e-11 153.2 153.2  7888       0          0  51.5 7801 .1307       5.138  .005062   \n","    llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  precision  recall  token_acc  token_em  \\\n","    13.1 8.542   1  13.1 674.9       0          0 5123      .3894  .08012      .1214         0   \n","    total_train_updates   tpb  tps  \n","                    155 166.3 8563\n","\u001b[0m\n","18:03:25 | creating task(s): personachat\n","18:03:25 | loading fbdialog data: /usr/local/lib/python3.10/dist-packages/data/Persona-Chat/personachat/test_self_original.txt\n","18:03:25 | running eval: test\n","18:05:51 | eval completed in 145.96s\n","18:05:51 | \u001b[1mtest:\n","    accuracy    bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gen_n_toks  gpu_mem  \\\n","           0 3.882e-11 149.6 149.6  7698       0          0 51.47 7512 .1355       5.127  .005077   \n","    llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  precision  recall  token_acc  token_em  \\\n","   12.96 8.521   1 12.96 667.2       0          0 5018      .4001  .08331      .1241         0   \n","    total_train_updates   tpb  tps  \n","                    155 162.5 8365\n","\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"nRJGRtMKmIWV","colab":{"base_uri":"https://localhost:8080/","height":373},"outputId":"1cb84c71-4ced-4df3-85ca-551833f845e5","executionInfo":{"status":"error","timestamp":1717609957499,"user_tz":420,"elapsed":297,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}}},"source":["# Import the Interactive script\n","from parlai.scripts.interactive import Interactive\n","\n","# call it with particular args\n","Interactive.main(\n","    # the model_file is a filename path pointing to a particular model dump.\n","    # Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\n","    # They'll be automatically downloaded when you ask to use them.\n","    model_file='agents:ir_baseline/model'\n",")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"WARNING: Model file does not exist, check to make sure it is correct: agents:ir_baseline/model","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f1006721a177>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# call it with particular args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m Interactive.main(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# the model_file is a filename path pointing to a particular model dump.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Model files that begin with \"zoo:\" are special files distributed by the ParlAI team.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/scripts/interactive.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/scripts/interactive.py\u001b[0m in \u001b[0;36minteractive\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Create model and assign it to the specified task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequireModelExists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mhuman_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalHumanAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/core/agents.py\u001b[0m in \u001b[0;36mcreate_agent\u001b[0;34m(opt, requireModelExists)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelzoo_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datapath'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequireModelExists\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;34m'WARNING: Model file does not exist, check to make '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;34m'sure it is correct: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: WARNING: Model file does not exist, check to make sure it is correct: agents:ir_baseline/model"]}]},{"cell_type":"markdown","metadata":{"id":"3hfUEgovmWay"},"source":["The same on the command line:\n","```bash\n","python -m parlai.scripts.interactive --model-file zoo:tutorial_transformer_generator/model\n","```"]},{"cell_type":"markdown","metadata":{"id":"o_hGrZGGmaWF"},"source":["# Taking a look at some data\n","\n","We can look at look into a specific dataset. Let's look into the \"empathetic dialogues\" dataset, which aims to teach models how to respond with text expressing the appropriate emotion. We have over existing 80 datasets in ParlAI. You can take a full look in our [task list](https://parl.ai/docs/tasks.html)."]},{"cell_type":"code","metadata":{"id":"AqckSXqlmWuT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618607985673,"user_tz":240,"elapsed":5012,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"e45fd031-547e-4389-c7c9-57819bfbbca0"},"source":["# The display_data script is used to show the contents of a particular task.\n","# By default, we show the train\n","from parlai.scripts.display_data import DisplayData\n","DisplayData.main(task='empathetic_dialogues', num_examples=5)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["21:19:40 | Opt:\n","21:19:40 |     allow_missing_init_opts: False\n","21:19:40 |     batchsize: 1\n","21:19:40 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n","21:19:40 |     datatype: train:ordered\n","21:19:40 |     dict_class: None\n","21:19:40 |     display_add_fields: \n","21:19:40 |     download_path: None\n","21:19:40 |     dynamic_batching: None\n","21:19:40 |     hide_labels: False\n","21:19:40 |     ignore_agent_reply: True\n","21:19:40 |     image_cropsize: 224\n","21:19:40 |     image_mode: raw\n","21:19:40 |     image_size: 256\n","21:19:40 |     init_model: None\n","21:19:40 |     init_opt: None\n","21:19:40 |     loglevel: info\n","21:19:40 |     max_display_len: 1000\n","21:19:40 |     model: None\n","21:19:40 |     model_file: None\n","21:19:40 |     multitask_weights: [1]\n","21:19:40 |     mutators: None\n","21:19:40 |     num_examples: 5\n","21:19:40 |     override: \"{'task': 'empathetic_dialogues', 'num_examples': 5}\"\n","21:19:40 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n","21:19:40 |     remove_political_convos: False\n","21:19:40 |     starttime: Apr16_21-19\n","21:19:40 |     task: empathetic_dialogues\n","21:19:40 |     train_experiencer_only: False\n","21:19:40 |     verbose: False\n","21:19:40 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? False, datatype: train:ordered\n","[building data: /usr/local/lib/python3.7/dist-packages/data/empatheticdialogues]\n","21:19:40 | Downloading http://parl.ai/downloads/empatheticdialogues/empatheticdialogues.tar.gz to /usr/local/lib/python3.7/dist-packages/data/empatheticdialogues/empatheticdialogues.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["Downloading empatheticdialogues.tar.gz: 100%|██████████| 28.0M/28.0M [00:02<00:00, 10.9MB/s]\n"],"name":"stderr"},{"output_type":"stream","text":["21:19:45 | \u001b[33mparlai.tasks.empathetic_dialogues.agents.DefaultTeacher' is outputting dicts instead of messages. If this is a teacher that is part of ParlAI, please file an issue on GitHub. If it is your own teacher, please return a Message object instead.\u001b[0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues - - -\u001b[0;0m\n","\u001b[0mI remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people, we felt like the only people in the world.\u001b[0;0m\n","   \u001b[1;94mWas this a friend you were in love with, or just a best friend?\u001b[0;0m\n","\u001b[0mThis was a best friend. I miss her.\u001b[0;0m\n","   \u001b[1;94mWhere has she gone?\u001b[0;0m\n","\u001b[0mWe no longer talk.\u001b[0;0m\n","   \u001b[1;94mOh was this something that happened because of an argument?\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues - - -\u001b[0;0m\n","\u001b[0mWas this a friend you were in love with, or just a best friend?\u001b[0;0m\n","   \u001b[1;94mThis was a best friend. I miss her.\u001b[0;0m\n","\u001b[0mWhere has she gone?\u001b[0;0m\n","   \u001b[1;94mWe no longer talk.\u001b[0;0m\n","21:19:45 | loaded 39057 episodes with a total of 64636 examples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a9C6oHq87zGx"},"source":["The black, unindented text is the _prompt_, while the blue text is the _label_. That is, the label is what we will be training the model to mimic.\n","\n","We can also ask to see fewer examples, and get them from the validation set instead."]},{"cell_type":"code","metadata":{"id":"RGNSBetWmfGF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618607990059,"user_tz":240,"elapsed":1066,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"5e13563e-a749-49f6-b6b0-19d2c7473448"},"source":["# we can instead ask to see fewer examples, and get them from the valid set.\n","DisplayData.main(task='empathetic_dialogues', num_examples=3, datatype='valid')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["21:19:49 | Opt:\n","21:19:49 |     allow_missing_init_opts: False\n","21:19:49 |     batchsize: 1\n","21:19:49 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n","21:19:49 |     datatype: valid\n","21:19:49 |     dict_class: None\n","21:19:49 |     display_add_fields: \n","21:19:49 |     download_path: None\n","21:19:49 |     dynamic_batching: None\n","21:19:49 |     hide_labels: False\n","21:19:49 |     ignore_agent_reply: True\n","21:19:49 |     image_cropsize: 224\n","21:19:49 |     image_mode: raw\n","21:19:49 |     image_size: 256\n","21:19:49 |     init_model: None\n","21:19:49 |     init_opt: None\n","21:19:49 |     loglevel: info\n","21:19:49 |     max_display_len: 1000\n","21:19:49 |     model: None\n","21:19:49 |     model_file: None\n","21:19:49 |     multitask_weights: [1]\n","21:19:49 |     mutators: None\n","21:19:49 |     num_examples: 3\n","21:19:49 |     override: \"{'task': 'empathetic_dialogues', 'num_examples': 3, 'datatype': 'valid'}\"\n","21:19:49 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n","21:19:49 |     remove_political_convos: False\n","21:19:49 |     starttime: Apr16_21-19\n","21:19:49 |     task: empathetic_dialogues\n","21:19:49 |     train_experiencer_only: False\n","21:19:49 |     verbose: False\n","21:19:49 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues - - -\u001b[0;0m\n","\u001b[0mToday,as i was leaving for work in the morning,i had a tire burst in the middle of a busy road. That scared the hell out of me!\u001b[0;0m\n","   \u001b[1;94mAre you fine now?\u001b[0;0m\n","\u001b[0mYeah,i'm doing alright now, but with minor injuries.\u001b[0;0m\n","   \u001b[1;94mCool :) Is your car damaged a lot?\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues - - -\u001b[0;0m\n","\u001b[0mA few weeks ago, I was walking through my hallway, minding my own business, when all of a sudden a hand reached out from under a table and grabbed my ankle. I was so suprised. I thought i was got. Turns out, it was my son. \u001b[0;0m\n","   \u001b[1;94mThat's funny, hope he didn't give you a heart attack.\u001b[0;0m\n","21:19:49 | loaded 2769 episodes with a total of 5738 examples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IVSrgRrEmdS-"},"source":["On the command line:\n","```bash\n","python -m parlai.scripts.display_data --task empathetic_dialogues\n","```\n","or a bit shorter\n","```\n","python -m parlai.scripts.display_data -t empathetic_dialogues\n","```"]},{"cell_type":"markdown","metadata":{"id":"9_M8Zr86n2_G"},"source":["# Training a model\n","\n","Well it's one thing looking at data, but what if we want to train our own model (from scratch)? Let's train a very simple seq2seq LSTM with attention, to respond to empathetic dialogues.\n","\n","To get some extra performance, we'll initialize using GloVe embeddings, but we will cap the training time to 2 minutes for this tutorial. It won't perform very well, but that's okay."]},{"cell_type":"code","metadata":{"id":"pBhVQycSn2q_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618608189123,"user_tz":240,"elapsed":194000,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"e424398c-1dc2-4bde-b723-6b2df62211cb"},"source":["# we'll save it in the \"from_scratch_model\" directory\n","!rm -rf from_scratch_model\n","!mkdir -p from_scratch_model\n","\n","from parlai.scripts.train_model import TrainModel\n","TrainModel.main(\n","    # we MUST provide a filename\n","    model_file='from_scratch_model/model',\n","    # train on empathetic dialogues\n","    task='empathetic_dialogues',\n","    # limit training time to 2 minutes, and a batchsize of 16\n","    max_train_time=2 * 60,\n","    batchsize=16,\n","\n","    # we specify the model type as seq2seq\n","    model='seq2seq',\n","    # some hyperparamter choices. We'll use attention. We could use pretrained\n","    # embeddings too, with embedding_type='fasttext', but they take a long\n","    # time to download.\n","    attention='dot',\n","    # tie the word embeddings of the encoder/decoder/softmax.\n","    lookuptable='all',\n","    # truncate text and labels at 64 tokens, for memory and time savings\n","    truncate=64,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["21:19:55 | building dictionary first...\n","21:19:55 | Opt:\n","21:19:55 |     adafactor_eps: '(1e-30, 0.001)'\n","21:19:55 |     adam_eps: 1e-08\n","21:19:55 |     add_p1_after_newln: False\n","21:19:55 |     aggregate_micro: False\n","21:19:55 |     allow_missing_init_opts: False\n","21:19:55 |     attention: dot\n","21:19:55 |     attention_length: 48\n","21:19:55 |     attention_time: post\n","21:19:55 |     batchsize: 1\n","21:19:55 |     beam_block_full_context: True\n","21:19:55 |     beam_block_list_filename: None\n","21:19:55 |     beam_block_ngram: -1\n","21:19:55 |     beam_context_block_ngram: -1\n","21:19:55 |     beam_delay: 30\n","21:19:55 |     beam_length_penalty: 0.65\n","21:19:55 |     beam_min_length: 1\n","21:19:55 |     beam_size: 1\n","21:19:55 |     betas: '(0.9, 0.999)'\n","21:19:55 |     bidirectional: False\n","21:19:55 |     bpe_add_prefix_space: None\n","21:19:55 |     bpe_debug: False\n","21:19:55 |     bpe_dropout: None\n","21:19:55 |     bpe_merge: None\n","21:19:55 |     bpe_vocab: None\n","21:19:55 |     compute_tokenized_bleu: False\n","21:19:55 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n","21:19:55 |     datatype: train\n","21:19:55 |     decoder: same\n","21:19:55 |     delimiter: '\\n'\n","21:19:55 |     dict_class: parlai.core.dict:DictionaryAgent\n","21:19:55 |     dict_endtoken: __end__\n","21:19:55 |     dict_file: from_scratch_model/model.dict\n","21:19:55 |     dict_include_test: False\n","21:19:55 |     dict_include_valid: False\n","21:19:55 |     dict_initpath: None\n","21:19:55 |     dict_language: english\n","21:19:55 |     dict_loaded: False\n","21:19:55 |     dict_lower: False\n","21:19:55 |     dict_max_ngram_size: -1\n","21:19:55 |     dict_maxexs: -1\n","21:19:55 |     dict_maxtokens: -1\n","21:19:55 |     dict_minfreq: 0\n","21:19:55 |     dict_nulltoken: __null__\n","21:19:55 |     dict_starttoken: __start__\n","21:19:55 |     dict_textfields: text,labels\n","21:19:55 |     dict_tokenizer: re\n","21:19:55 |     dict_unktoken: __unk__\n","21:19:55 |     display_examples: False\n","21:19:55 |     download_path: None\n","21:19:55 |     dropout: 0.1\n","21:19:55 |     dynamic_batching: None\n","21:19:55 |     embedding_projection: random\n","21:19:55 |     embedding_type: random\n","21:19:55 |     embeddingsize: 128\n","21:19:55 |     eval_batchsize: None\n","21:19:55 |     eval_dynamic_batching: None\n","21:19:55 |     evaltask: None\n","21:19:55 |     force_fp16_tokens: False\n","21:19:55 |     fp16: False\n","21:19:55 |     fp16_impl: safe\n","21:19:55 |     gpu: -1\n","21:19:55 |     gradient_clip: 0.1\n","21:19:55 |     hiddensize: 128\n","21:19:55 |     hide_labels: False\n","21:19:55 |     history_add_global_end_token: None\n","21:19:55 |     history_reversed: False\n","21:19:55 |     history_size: -1\n","21:19:55 |     image_cropsize: 224\n","21:19:55 |     image_mode: no_image_model\n","21:19:55 |     image_size: 256\n","21:19:55 |     inference: greedy\n","21:19:55 |     init_model: None\n","21:19:55 |     init_opt: None\n","21:19:55 |     input_dropout: 0.0\n","21:19:55 |     interactive_mode: False\n","21:19:55 |     invsqrt_lr_decay_gamma: -1\n","21:19:55 |     label_truncate: None\n","21:19:55 |     learningrate: 1\n","21:19:55 |     load_from_checkpoint: True\n","21:19:55 |     log_every_n_secs: 10\n","21:19:55 |     loglevel: info\n","21:19:55 |     lookuptable: all\n","21:19:55 |     lr_scheduler: reduceonplateau\n","21:19:55 |     lr_scheduler_decay: 0.5\n","21:19:55 |     lr_scheduler_patience: 3\n","21:19:55 |     max_lr_steps: -1\n","21:19:55 |     max_train_time: 120.0\n","21:19:55 |     metrics: default\n","21:19:55 |     model: seq2seq\n","21:19:55 |     model_file: from_scratch_model/model\n","21:19:55 |     momentum: 0\n","21:19:55 |     multitask_weights: [1]\n","21:19:55 |     mutators: None\n","21:19:55 |     nesterov: True\n","21:19:55 |     no_cuda: False\n","21:19:55 |     num_epochs: -1\n","21:19:55 |     numlayers: 2\n","21:19:55 |     numsoftmax: 1\n","21:19:55 |     nus: (0.7,)\n","21:19:55 |     optimizer: sgd\n","21:19:55 |     override: \"{'model_file': 'from_scratch_model/model', 'task': 'empathetic_dialogues', 'max_train_time': 120.0, 'batchsize': 16, 'model': 'seq2seq', 'attention': 'dot', 'lookuptable': 'all', 'truncate': 64}\"\n","21:19:55 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n","21:19:55 |     person_tokens: False\n","21:19:55 |     rank_candidates: False\n","21:19:55 |     remove_political_convos: False\n","21:19:55 |     rnn_class: lstm\n","21:19:55 |     save_after_valid: False\n","21:19:55 |     save_every_n_secs: -1\n","21:19:55 |     short_final_eval: False\n","21:19:55 |     skip_generation: False\n","21:19:55 |     special_tok_lst: None\n","21:19:55 |     split_lines: False\n","21:19:55 |     starttime: Apr16_21-19\n","21:19:55 |     task: empathetic_dialogues\n","21:19:55 |     temperature: 1.0\n","21:19:55 |     tensorboard_log: False\n","21:19:55 |     tensorboard_logdir: None\n","21:19:55 |     text_truncate: None\n","21:19:55 |     topk: 10\n","21:19:55 |     topp: 0.9\n","21:19:55 |     train_experiencer_only: False\n","21:19:55 |     truncate: 64\n","21:19:55 |     update_freq: 1\n","21:19:55 |     use_reply: label\n","21:19:55 |     validation_cutoff: 1.0\n","21:19:55 |     validation_every_n_epochs: -1\n","21:19:55 |     validation_every_n_secs: -1\n","21:19:55 |     validation_max_exs: -1\n","21:19:55 |     validation_metric: accuracy\n","21:19:55 |     validation_metric_mode: None\n","21:19:55 |     validation_patience: 10\n","21:19:55 |     validation_share_agent: False\n","21:19:55 |     verbose: False\n","21:19:55 |     wandb_log: False\n","21:19:55 |     wandb_name: None\n","21:19:55 |     wandb_project: None\n","21:19:55 |     warmup_rate: 0.0001\n","21:19:55 |     warmup_updates: -1\n","21:19:55 |     weight_decay: None\n","21:19:56 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? False, datatype: train:ordered:stream\n"],"name":"stdout"},{"output_type":"stream","text":["Building dictionary: 100%|██████████| 64.6k/64.6k [00:02<00:00, 23.1kex/s]\n"],"name":"stderr"},{"output_type":"stream","text":["21:19:59 | Saving dictionary to from_scratch_model/model.dict\n","21:19:59 | dictionary built with 22419 tokens in 0.0s\n","21:19:59 | No model with opt yet at: from_scratch_model/model(.opt)\n","21:19:59 | Using CUDA\n","21:19:59 | loading dictionary from from_scratch_model/model.dict\n","21:19:59 | num words = 22419\n","21:19:59 | Total parameters: 3,453,203 (3,453,203 trainable)\n","21:19:59 | Opt:\n","21:19:59 |     adafactor_eps: '(1e-30, 0.001)'\n","21:19:59 |     adam_eps: 1e-08\n","21:19:59 |     add_p1_after_newln: False\n","21:19:59 |     aggregate_micro: False\n","21:19:59 |     allow_missing_init_opts: False\n","21:19:59 |     attention: dot\n","21:19:59 |     attention_length: 48\n","21:19:59 |     attention_time: post\n","21:19:59 |     batchsize: 16\n","21:19:59 |     beam_block_full_context: True\n","21:19:59 |     beam_block_list_filename: None\n","21:19:59 |     beam_block_ngram: -1\n","21:19:59 |     beam_context_block_ngram: -1\n","21:19:59 |     beam_delay: 30\n","21:19:59 |     beam_length_penalty: 0.65\n","21:19:59 |     beam_min_length: 1\n","21:19:59 |     beam_size: 1\n","21:19:59 |     betas: '(0.9, 0.999)'\n","21:19:59 |     bidirectional: False\n","21:19:59 |     bpe_add_prefix_space: None\n","21:19:59 |     bpe_debug: False\n","21:19:59 |     bpe_dropout: None\n","21:19:59 |     bpe_merge: None\n","21:19:59 |     bpe_vocab: None\n","21:19:59 |     compute_tokenized_bleu: False\n","21:19:59 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n","21:19:59 |     datatype: train\n","21:19:59 |     decoder: same\n","21:19:59 |     delimiter: '\\n'\n","21:19:59 |     dict_class: parlai.core.dict:DictionaryAgent\n","21:19:59 |     dict_endtoken: __end__\n","21:19:59 |     dict_file: from_scratch_model/model.dict\n","21:19:59 |     dict_include_test: False\n","21:19:59 |     dict_include_valid: False\n","21:19:59 |     dict_initpath: None\n","21:19:59 |     dict_language: english\n","21:19:59 |     dict_loaded: True\n","21:19:59 |     dict_lower: False\n","21:19:59 |     dict_max_ngram_size: -1\n","21:19:59 |     dict_maxexs: -1\n","21:19:59 |     dict_maxtokens: -1\n","21:19:59 |     dict_minfreq: 0\n","21:19:59 |     dict_nulltoken: __null__\n","21:19:59 |     dict_starttoken: __start__\n","21:19:59 |     dict_textfields: text,labels\n","21:19:59 |     dict_tokenizer: re\n","21:19:59 |     dict_unktoken: __unk__\n","21:19:59 |     display_examples: False\n","21:19:59 |     download_path: None\n","21:19:59 |     dropout: 0.1\n","21:19:59 |     dynamic_batching: None\n","21:19:59 |     embedding_projection: random\n","21:19:59 |     embedding_type: random\n","21:19:59 |     embeddingsize: 128\n","21:19:59 |     eval_batchsize: None\n","21:19:59 |     eval_dynamic_batching: None\n","21:19:59 |     evaltask: None\n","21:19:59 |     force_fp16_tokens: False\n","21:19:59 |     fp16: False\n","21:19:59 |     fp16_impl: safe\n","21:19:59 |     gpu: -1\n","21:19:59 |     gradient_clip: 0.1\n","21:19:59 |     hiddensize: 128\n","21:19:59 |     hide_labels: False\n","21:19:59 |     history_add_global_end_token: None\n","21:19:59 |     history_reversed: False\n","21:19:59 |     history_size: -1\n","21:19:59 |     image_cropsize: 224\n","21:19:59 |     image_mode: raw\n","21:19:59 |     image_size: 256\n","21:19:59 |     inference: greedy\n","21:19:59 |     init_model: None\n","21:19:59 |     init_opt: None\n","21:19:59 |     input_dropout: 0.0\n","21:19:59 |     interactive_mode: False\n","21:19:59 |     invsqrt_lr_decay_gamma: -1\n","21:19:59 |     label_truncate: None\n","21:19:59 |     learningrate: 1\n","21:19:59 |     load_from_checkpoint: True\n","21:19:59 |     log_every_n_secs: 10\n","21:19:59 |     loglevel: info\n","21:19:59 |     lookuptable: all\n","21:19:59 |     lr_scheduler: reduceonplateau\n","21:19:59 |     lr_scheduler_decay: 0.5\n","21:19:59 |     lr_scheduler_patience: 3\n","21:19:59 |     max_lr_steps: -1\n","21:19:59 |     max_train_time: 120.0\n","21:19:59 |     metrics: default\n","21:19:59 |     model: seq2seq\n","21:19:59 |     model_file: from_scratch_model/model\n","21:19:59 |     momentum: 0\n","21:19:59 |     multitask_weights: [1]\n","21:19:59 |     mutators: None\n","21:19:59 |     nesterov: True\n","21:19:59 |     no_cuda: False\n","21:19:59 |     num_epochs: -1\n","21:19:59 |     numlayers: 2\n","21:19:59 |     numsoftmax: 1\n","21:19:59 |     nus: (0.7,)\n","21:19:59 |     optimizer: sgd\n","21:19:59 |     override: \"{'model_file': 'from_scratch_model/model', 'task': 'empathetic_dialogues', 'max_train_time': 120.0, 'batchsize': 16, 'model': 'seq2seq', 'attention': 'dot', 'lookuptable': 'all', 'truncate': 64}\"\n","21:19:59 |     parlai_home: /usr/local/lib/python3.7/dist-packages\n","21:19:59 |     person_tokens: False\n","21:19:59 |     rank_candidates: False\n","21:19:59 |     remove_political_convos: False\n","21:19:59 |     rnn_class: lstm\n","21:19:59 |     save_after_valid: False\n","21:19:59 |     save_every_n_secs: -1\n","21:19:59 |     short_final_eval: False\n","21:19:59 |     skip_generation: False\n","21:19:59 |     special_tok_lst: None\n","21:19:59 |     split_lines: False\n","21:19:59 |     starttime: Apr16_21-19\n","21:19:59 |     task: empathetic_dialogues\n","21:19:59 |     temperature: 1.0\n","21:19:59 |     tensorboard_log: False\n","21:19:59 |     tensorboard_logdir: None\n","21:19:59 |     text_truncate: None\n","21:19:59 |     topk: 10\n","21:19:59 |     topp: 0.9\n","21:19:59 |     train_experiencer_only: False\n","21:19:59 |     truncate: 64\n","21:19:59 |     update_freq: 1\n","21:19:59 |     use_reply: label\n","21:19:59 |     validation_cutoff: 1.0\n","21:19:59 |     validation_every_n_epochs: -1\n","21:19:59 |     validation_every_n_secs: -1\n","21:19:59 |     validation_max_exs: -1\n","21:19:59 |     validation_metric: accuracy\n","21:19:59 |     validation_metric_mode: None\n","21:19:59 |     validation_patience: 10\n","21:19:59 |     validation_share_agent: False\n","21:19:59 |     verbose: False\n","21:19:59 |     wandb_log: False\n","21:19:59 |     wandb_name: None\n","21:19:59 |     wandb_project: None\n","21:19:59 |     warmup_rate: 0.0001\n","21:19:59 |     warmup_updates: -1\n","21:19:59 |     weight_decay: None\n","21:20:00 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? False, datatype: train\n","21:20:00 | training...\n","21:20:10 | time:10s total_exs:2432 epochs:0.04\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 458.4  6937 242.1 2432  1.009   .02616 9.008   1 256.2  3877 8172     .09417                  152 714.6 10814 15.13\n","\n","21:20:20 | time:20s total_exs:4960 epochs:0.08\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 444.7  6991 251.5 2528  1.093   .02616 8.364   1 257.6  4050 4289      .1293                  310 702.3 11040 15.72\n","\n","21:20:30 | time:30s total_exs:7408 epochs:0.11\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 447.4  6812 243.6 2448  1.152   .02616 7.967   1 256.8  3910 2883      .1478                  463 704.3 10722 15.22\n","\n","21:20:40 | time:40s total_exs:9808 epochs:0.15\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 457.2  6843 239.5 2400  1.189   .02617 7.736   1 262.1  3923 2290      .1529                  613 719.3 10766 14.97\n","\n","21:20:51 | time:50s total_exs:12272 epochs:0.19\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 452.6  6937 245.2 2464  1.232   .02617  7.51   1 258.7  3965 1827      .1636                  767 711.2 10902 15.33\n","\n","21:21:01 | time:60s total_exs:14752 epochs:0.23\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps  ups\n","       1 454.2  7039 247.9 2480  1.238   .02617 7.344   1 262.7  4071 1547      .1683                  922 716.9 11110 15.5\n","\n","21:21:11 | time:70s total_exs:17168 epochs:0.27\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 448.7  6751 240.7 2416  1.264   .02617 7.181   1 262.8  3954 1315      .1753                 1073 711.5 10705 15.05\n","\n","21:21:21 | time:80s total_exs:19600 epochs:0.30\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 450.9  6837 242.6 2432  1.295   .02617  7.03   1 262.7  3982 1130      .1814                 1225 713.6 10819 15.16\n","\n","21:21:31 | time:90s total_exs:22064 epochs:0.34\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps  ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 453.1  6964 245.9 2464  1.318   .02617 6.946   1 257.5  3958 1039      .1835                 1379 710.6 10922 15.37\n","\n","21:21:41 | time:101s total_exs:24528 epochs:0.38\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps   ppl  token_acc  total_train_updates   tpb   tps   ups\n","       1 455.7  6990 245.4 2464  1.322    .0261 6.869   1 261.9  4017 961.8      .1863                 1533 717.6 11007 15.34\n","\n","21:21:51 | time:111s total_exs:26960 epochs:0.42\n","    clip  ctpb  ctps  exps  exs  gnorm  gpu_mem  loss  lr  ltpb  ltps   ppl  token_acc  total_train_updates  tpb   tps   ups\n","       1 449.1  6811 242.6 2432   1.35   .02618 6.813   1 258.9  3926 909.3      .1854                 1685  708 10737 15.16\n","\n","21:22:00 | max_train_time elapsed:120.02368354797363s\n","21:22:00 | Using CUDA\n","21:22:00 | loading dictionary from from_scratch_model/model.dict\n","21:22:00 | num words = 22419\n","21:22:00 | Total parameters: 3,453,203 (3,453,203 trainable)\n","21:22:00 | Loading existing model params from from_scratch_model/model\n","21:22:00 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n","21:22:01 | running eval: valid\n","21:22:36 | eval completed in 34.88s\n","21:22:36 | \u001b[1mvalid:\n","    accuracy    bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  lr  ltpb  ltps   ppl  token_acc  total_train_updates  \\\n","           0 8.027e-07 572.6  5913 164.6 5738 .1084 .0009844 6.406   1 249.1  2572 605.5      .2173                 1826   \n","     tpb  tps  \n","   821.7 8486\n","\u001b[0m\n","21:22:36 | creating task(s): empathetic_dialogues\n","[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: test\n","21:22:36 | running eval: test\n","21:23:08 | eval completed in 32.26s\n","21:23:08 | \u001b[1mtest:\n","    accuracy    bleu-4  ctpb  ctps  exps  exs    f1  gpu_mem  loss  lr  ltpb  ltps   ppl  token_acc  total_train_updates  \\\n","           0 9.994e-07 604.5  6168 163.1 5259 .1081 .0009528 6.425   1 252.6  2577 617.4      .2153                 1826   \n","     tpb  tps  \n","   857.1 8745\n","\u001b[0m\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["({'accuracy': ExactMatchMetric(0),\n","  'bleu-4': BleuMetric(8.027e-07),\n","  'ctpb': GlobalAverageMetric(572.6),\n","  'ctps': GlobalTimerMetric(5913),\n","  'exps': GlobalTimerMetric(164.6),\n","  'exs': SumMetric(5738),\n","  'f1': F1Metric(0.1084),\n","  'gpu_mem': GlobalAverageMetric(0.0009844),\n","  'loss': AverageMetric(6.406),\n","  'lr': GlobalAverageMetric(1),\n","  'ltpb': GlobalAverageMetric(249.1),\n","  'ltps': GlobalTimerMetric(2572),\n","  'ppl': PPLMetric(605.5),\n","  'token_acc': AverageMetric(0.2173),\n","  'total_train_updates': GlobalFixedMetric(1826),\n","  'tpb': GlobalAverageMetric(821.7),\n","  'tps': GlobalTimerMetric(8486)},\n"," {'accuracy': ExactMatchMetric(0),\n","  'bleu-4': BleuMetric(9.994e-07),\n","  'ctpb': GlobalAverageMetric(604.5),\n","  'ctps': GlobalTimerMetric(6168),\n","  'exps': GlobalTimerMetric(163.1),\n","  'exs': SumMetric(5259),\n","  'f1': F1Metric(0.1081),\n","  'gpu_mem': GlobalAverageMetric(0.0009528),\n","  'loss': AverageMetric(6.425),\n","  'lr': GlobalAverageMetric(1),\n","  'ltpb': GlobalAverageMetric(252.6),\n","  'ltps': GlobalTimerMetric(2577),\n","  'ppl': PPLMetric(617.4),\n","  'token_acc': AverageMetric(0.2153),\n","  'total_train_updates': GlobalFixedMetric(1826),\n","  'tpb': GlobalAverageMetric(857.1),\n","  'tps': GlobalTimerMetric(8745)})"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"SvA77Zwkoviq"},"source":["Our perplexity and F1 (word overlap) scores are pretty bad, and our BLEU-4 score is nearly 0. That's okay, we would normally want to train for well over an hour. Feel free to change the max_train_time above."]},{"cell_type":"markdown","metadata":{"id":"_QTiTn7aoxv9"},"source":["## Performance is pretty bad there. Can we improve it?\n","\n","The easiest way to improve it is to *initialize* using a *pretrained model*, utilizing *transfer learning*. Let's use the one from the interactive session at the beginning of the chat!"]},{"cell_type":"code","metadata":{"id":"O2Jt9bHTn1dP","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1717610092258,"user_tz":420,"elapsed":2339,"user":{"displayName":"SIDDARTH CHALASANI","userId":"03877369754210018754"}},"outputId":"e3de53e2-3954-4e09-fc07-c7d8e44eebb6"},"source":["!rm -rf from_pretrained\n","!mkdir -p from_pretrained\n","\n","from parlai.scripts.train_model import TrainModel\n","TrainModel.main(\n","    # similar to before\n","    task='personachat',\n","    model='seq2seq',\n","    #model_file='from_pretrained/model',\n","\n","    # initialize with a pretrained model\n","    #init_model='zoo:tutorial_transformer_generator/model',\n","\n","    # arguments we get from the pretrained model.\n","    # Unfortunately, these must be looked up separately for each model.\n","    #n_heads=16, n_layers=8, n_positions=512, text_truncate=512,\n","    #label_truncate=128, ffn_size=2048, embedding_size=512,\n","    #activation='gelu', variant='xlm',\n","    #dict_lower=True, dict_tokenizer='bpe',\n","    #dict_file='zoo:tutorial_transformer_generator/model.dict',\n","    #learn_positional_embeddings=True,\n","\n","    # some training arguments, specific to this fine-tuning\n","    # use a small learning rate with ADAM optimizer\n","    #lr=1e-5, optimizer='adam',\n","    #warmup_updates=100,\n","    # early stopping on perplexity\n","    #validation_metric='ppl',\n","    # train at most 10 minutes, and validate every 0.25 epochs\n","    #max_train_time=600, validation_every_n_epochs=0.25,\n","\n","    # depend on your gpu. If you have a V100, this is good\n","    #batchsize=12, fp16=True, fp16_impl='mem_efficient',\n","\n","    # speeds up validation\n","    skip_generation=True,\n","\n","    # helps us cram more examples into our gpu at a time\n","    #dynamic_batching='full',\n",")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"WARNING: For train_model, please specify either a model_file or dict_file.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-8e9346cd5e78>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparlai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m TrainModel.main(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# similar to before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'personachat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_from_parser_and_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/core/script.py\u001b[0m in \u001b[0;36m_run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/parlai/scripts/train_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m# Possibly build a dictionary (not all models do this).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dict_file'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    370\u001b[0m                 \u001b[0;34m'WARNING: For train_model, please specify either a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                 \u001b[0;34m'model_file or dict_file.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: WARNING: For train_model, please specify either a model_file or dict_file."]}]},{"cell_type":"markdown","metadata":{"id":"0iBZXTLRvIjb"},"source":["## Wow that's a lot of options? Where do I find more info?\n","\n","As you might have noticed, there are a LOT of options to ParlAI. You're best reading the [ParlAI docs](https://parl.ai/docs) to find a list of hyperparameters. We provide lists of the command-line args for both models\n","\n","You can get some guidance in this notebook by using:"]},{"cell_type":"code","metadata":{"id":"0Pl8VVl5plfm","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1587094704861,"user_tz":240,"elapsed":636,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"453c1f82-a7ff-4df7-c7ad-f728c6e67854"},"source":["# note that if you want to see model-specific arguments, you must specify a model name\n","print(TrainModel.help(model='seq2seq'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["usage: TrainModel [-h] [-o INIT_OPT] [-v] [-t TASK]\n","                  [-dt {train,train:stream,train:ordered,train:ordered:stream,train:stream:ordered,train:evalmode,train:evalmode:stream,train:evalmode:ordered,train:evalmode:ordered:stream,train:evalmode:stream:ordered,valid,valid:stream,test,test:stream}]\n","                  [-nt NUMTHREADS] [-bs BATCHSIZE] [-dynb {None,batchsort,full}]\n","                  [-dp DATAPATH] [-m MODEL] [-mf MODEL_FILE] [-im INIT_MODEL]\n","                  [-et EVALTASK] [-eps NUM_EPOCHS] [-ttim MAX_TRAIN_TIME]\n","                  [-vtim VALIDATION_EVERY_N_SECS] [-stim SAVE_EVERY_N_SECS]\n","                  [-sval SAVE_AFTER_VALID] [-veps VALIDATION_EVERY_N_EPOCHS]\n","                  [-vp VALIDATION_PATIENCE] [-vmt VALIDATION_METRIC]\n","                  [-vmm {max,min}] [-mcs METRICS] [-micro AGGREGATE_MICRO]\n","                  [-tblog TENSORBOARD_LOG] [-hs HIDDENSIZE] [-esz EMBEDDINGSIZE]\n","                  [-nl NUMLAYERS] [-dr DROPOUT] [-bi BIDIRECTIONAL]\n","                  [-att {none,concat,general,dot,local}]\n","                  [-attl ATTENTION_LENGTH] [--attention-time {pre,post}]\n","                  [-rnn {rnn,gru,lstm}] [-dec {same,shared}]\n","                  [-lt {unique,enc_dec,dec_out,all}] [-soft NUMSOFTMAX]\n","                  [-idr INPUT_DROPOUT] [--beam-size BEAM_SIZE]\n","                  [--beam-min-length BEAM_MIN_LENGTH]\n","                  [--beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM]\n","                  [--beam-block-ngram BEAM_BLOCK_NGRAM]\n","                  [--beam-length-penalty BEAM_LENGTH_PENALTY]\n","                  [--inference {topk,beam,nucleus,delayedbeam,greedy}]\n","                  [--topk TOPK] [--topp TOPP] [--beam-delay BEAM_DELAY]\n","                  [--temperature TEMPERATURE]\n","                  [--compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU]\n","                  [-i INTERACTIVE_MODE]\n","                  [-emb {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}]\n","                  [-embp EMBEDDING_PROJECTION] [--fp16 FP16]\n","                  [--fp16-impl {apex,mem_efficient}]\n","                  [-opt {adadelta,adagrad,adam,adamw,sparseadam,adamax,asgd,sgd,rprop,rmsprop,optimizer,lbfgs,mem_eff_adam,adafactor}]\n","                  [-lr LEARNINGRATE] [-clip GRADIENT_CLIP]\n","                  [--adafactor-eps ADAFACTOR_EPS] [-mom MOMENTUM]\n","                  [--nesterov NESTEROV] [-nu NUS] [-beta BETAS]\n","                  [-wdecay WEIGHT_DECAY] [-rc RANK_CANDIDATES] [-tr TRUNCATE]\n","                  [--text-truncate TEXT_TRUNCATE]\n","                  [--label-truncate LABEL_TRUNCATE] [-histsz HISTORY_SIZE]\n","                  [-pt PERSON_TOKENS] [--split-lines SPLIT_LINES]\n","                  [--delimiter DELIMITER] [-gpu GPU | --no-cuda]\n","                  [--bpe-vocab BPE_VOCAB] [--bpe-merge BPE_MERGE]\n","                  [--lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}]\n","                  [--lr-scheduler-patience LR_SCHEDULER_PATIENCE]\n","                  [--lr-scheduler-decay LR_SCHEDULER_DECAY]\n","                  [--max-lr-steps MAX_LR_STEPS]\n","                  [--invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA]\n","\n","Train a model\n","\n","optional arguments:\n","  -h, --help\n","      show this help message and exit\n","\n","Main ParlAI Arguments:\n","  -o, --init-opt INIT_OPT\n","      Path to json file of options. Note: Further Command-line arguments\n","      override file-based options. (default: None)\n","  -v, --show-advanced-args\n","      Show hidden command line options (advanced users only) (default: False)\n","  -t, --task TASK\n","      ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: None)\n","  -dt, --datatype {train,train:stream,train:ordered,train:ordered:stream,train:stream:ordered,train:evalmode,train:evalmode:stream,train:evalmode:ordered,train:evalmode:ordered:stream,train:evalmode:stream:ordered,valid,valid:stream,test,test:stream}\n","      choose from: train, train:ordered, valid, test. to stream data add\n","      \":stream\" to any option (e.g., train:stream). by default: train is random\n","      with replacement, valid is ordered, test is ordered. (default: train)\n","  -nt, --numthreads NUMTHREADS\n","      number of threads. Used for hogwild if batchsize is 1, else for number of\n","      threads in threadpool loading, (default: 1)\n","  -bs, --batchsize BATCHSIZE\n","      batch size for minibatch training schemes (default: 1)\n","  -dynb, --dynamic-batching {None,batchsort,full}\n","      Use dynamic batching (default: None)\n","  -dp, --datapath DATAPATH\n","      path to datasets, defaults to {parlai_dir}/data (default: None)\n","\n","ParlAI Model Arguments:\n","  -m, --model MODEL\n","      the model class name. can match parlai/agents/<model> for agents in that\n","      directory, or can provide a fully specified module for `from X import Y`\n","      via `-m X:Y` (e.g. `-m parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`)\n","      (default: None)\n","  -mf, --model-file MODEL_FILE\n","      model file name for loading and saving models (default: None)\n","  -im, --init-model INIT_MODEL\n","      load model weights and dict from this file (default: None)\n","\n","Training Loop Arguments:\n","  -et, --evaltask EVALTASK\n","      task to use for valid/test (defaults to the one used for training)\n","      (default: None)\n","  -eps, --num-epochs NUM_EPOCHS\n","  -ttim, --max-train-time MAX_TRAIN_TIME\n","  -vtim, --validation-every-n-secs VALIDATION_EVERY_N_SECS\n","      Validate every n seconds. Saves model to model_file (if set) whenever best\n","      val metric is found (default: -1)\n","  -stim, --save-every-n-secs SAVE_EVERY_N_SECS\n","      Saves the model to model_file.checkpoint after every n seconds (default\n","      -1, never). (default: -1)\n","  -sval, --save-after-valid SAVE_AFTER_VALID\n","      Saves the model to model_file.checkpoint after every validation (default\n","      False).\n","  -veps, --validation-every-n-epochs VALIDATION_EVERY_N_EPOCHS\n","      Validate every n epochs. Saves model to model_file (if set) whenever best\n","      val metric is found (default: -1)\n","  -vp, --validation-patience VALIDATION_PATIENCE\n","      number of iterations of validation where result does not improve before we\n","      stop training (default: 10)\n","  -vmt, --validation-metric VALIDATION_METRIC\n","      key into report table for selecting best validation (default: accuracy)\n","  -vmm, --validation-metric-mode {max,min}\n","      how to optimize validation metric (max or min) (default: None)\n","  -mcs, --metrics METRICS\n","      list of metrics to show/compute, e.g. all, default,or give a list split by\n","      , like ppl,f1,accuracy,hits@1,rouge,bleuthe rouge metrics will be computed\n","      as rouge-1, rouge-2 and rouge-l (default: default)\n","  -micro, --aggregate-micro AGGREGATE_MICRO\n","      Report micro-averaged metrics instead of macro averaged metrics. (default:\n","      False)\n","\n","Tensorboard Arguments:\n","  -tblog, --tensorboard-log TENSORBOARD_LOG\n","      Tensorboard logging of metrics, default is False\n","\n","Seq2Seq Arguments:\n","  -hs, --hiddensize HIDDENSIZE\n","      size of the hidden layers (default: 128)\n","  -esz, --embeddingsize EMBEDDINGSIZE\n","      size of the token embeddings (default: 128)\n","  -nl, --numlayers NUMLAYERS\n","      number of hidden layers (default: 2)\n","  -dr, --dropout DROPOUT\n","      dropout rate (default: 0.1)\n","  -bi, --bidirectional BIDIRECTIONAL\n","      whether to encode the context with a bidirectional rnn (default: False)\n","  -att, --attention {none,concat,general,dot,local}\n","      Choices: none, concat, general, local. If set local, also set attention-\n","      length. (see arxiv.org/abs/1508.04025) (default: none)\n","  -attl, --attention-length ATTENTION_LENGTH\n","      Length of local attention. (default: 48)\n","  --attention-time {pre,post}\n","      Whether to apply attention before or after decoding. (default: post)\n","  -rnn, --rnn-class {rnn,gru,lstm}\n","      Choose between different types of RNNs. (default: lstm)\n","  -dec, --decoder {same,shared}\n","      Choose between different decoder modules. Default \"same\" uses same class\n","      as encoder, while \"shared\" also uses the same weights. Note that shared\n","      disabled some encoder options--in particular, bidirectionality. (default:\n","      same)\n","  -lt, --lookuptable {unique,enc_dec,dec_out,all}\n","      The encoder, decoder, and output modules can share weights, or not. Unique\n","      has independent embeddings for each. Enc_dec shares the embedding for the\n","      encoder and decoder. Dec_out shares decoder embedding and output weights.\n","      All shares all three weights. (default: unique)\n","  -soft, --numsoftmax NUMSOFTMAX\n","      default 1, if greater then uses mixture of softmax (see\n","      arxiv.org/abs/1711.03953). (default: 1)\n","  -idr, --input-dropout INPUT_DROPOUT\n","      Probability of replacing tokens with UNK in training. (default: 0.0)\n","\n","Torch Generator Agent:\n","  --beam-size BEAM_SIZE\n","      Beam size, if 1 then greedy search (default: 1)\n","  --beam-min-length BEAM_MIN_LENGTH\n","      Minimum length of prediction to be generated by the beam search (default:\n","      1)\n","  --beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM\n","      Size n-grams to block in beam search from the context. val <= 0 implies no\n","      blocking (default: -1)\n","  --beam-block-ngram BEAM_BLOCK_NGRAM\n","      Size n-grams to block in beam search. val <= 0 implies no blocking\n","      (default: -1)\n","  --beam-length-penalty BEAM_LENGTH_PENALTY\n","      Applies a length penalty. Set to 0 for no penalty. (default: 0.65)\n","  --inference {topk,beam,nucleus,delayedbeam,greedy}\n","      Generation algorithm (default: greedy)\n","  --topk TOPK\n","      K used in Top K sampling (default: 10)\n","  --topp TOPP\n","      p used in nucleus sampling (default: 0.9)\n","  --beam-delay BEAM_DELAY\n","      used in delayedbeam search (default: 30)\n","  --temperature TEMPERATURE\n","      temperature to add during decoding (default: 1.0)\n","  --compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU\n","      if true, compute tokenized bleu scores (default: False)\n","\n","TorchAgent Arguments:\n","  -i, --interactive-mode INTERACTIVE_MODE\n","      Whether in full interactive mode or not, which means generating text or\n","      retrieving from a full set of candidates, which is necessary to actually\n","      do full dialogue. However, during training or quick validation (e.g. PPL\n","      for generation or ranking a few candidates for ranking models) you might\n","      want these set to off. Typically, scripts can set their preferred default\n","      behavior at the start, e.g. eval scripts. (default: False)\n","  -emb, --embedding-type {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}\n","      Choose between different strategies for initializing word embeddings.\n","      Default is random, but can also preinitialize from Glove or Fasttext.\n","      Preinitialized embeddings can also be fixed so they are not updated during\n","      training. (default: random)\n","  -embp, --embedding-projection EMBEDDING_PROJECTION\n","      If pretrained embeddings have a different dimensionality than your\n","      embedding size, strategy for projecting to the correct size. If the\n","      dimensions are the same, this is ignored unless you append \"-force\" to\n","      your choice. (default: random)\n","  --fp16 FP16\n","      Use fp16 computations. (default: False)\n","  --fp16-impl {apex,mem_efficient}\n","      Implementation of FP16 to use (default: apex)\n","  -rc, --rank-candidates RANK_CANDIDATES\n","      Whether the model should parse candidates for ranking. (default: False)\n","  -tr, --truncate TRUNCATE\n","      Truncate input lengths to increase speed / use less memory. (default: -1)\n","  --text-truncate TEXT_TRUNCATE\n","      Text input truncation length: if not specified, this will default to\n","      `truncate` (default: None)\n","  --label-truncate LABEL_TRUNCATE\n","      Label truncation length: if not specified, this will default to `truncate`\n","      (default: None)\n","  -histsz, --history-size HISTORY_SIZE\n","      Number of past dialog utterances to remember. (default: -1)\n","  -pt, --person-tokens PERSON_TOKENS\n","      add person tokens to history. adds __p1__ in front of input text and\n","      __p2__ in front of past labels when available or past utterances generated\n","      by the model. these are added to the dictionary during initialization.\n","      (default: False)\n","  --split-lines SPLIT_LINES\n","      split the dialogue history on newlines and save in separate vectors\n","      (default: False)\n","  --delimiter DELIMITER\n","      Join history lines with this token, defaults to newline (default: )\n","  -gpu, --gpu GPU\n","      which GPU to use (default: -1)\n","  --no-cuda\n","      disable GPUs even if available. otherwise, will use GPUs if available on\n","      the device. (default: False)\n","\n","Optimizer Arguments:\n","  -opt, --optimizer {adadelta,adagrad,adam,adamw,sparseadam,adamax,asgd,sgd,rprop,rmsprop,optimizer,lbfgs,mem_eff_adam,adafactor}\n","      Choose between pytorch optimizers. Any member of torch.optim should be\n","      valid. (default: sgd)\n","  -lr, --learningrate LEARNINGRATE\n","      Learning rate (default: 1)\n","  -clip, --gradient-clip GRADIENT_CLIP\n","      gradient clipping using l2 norm (default: 0.1)\n","  --adafactor-eps ADAFACTOR_EPS\n","      Epsilon values for adafactor optimizer: regularization constants for\n","      square gradient and parameter scale respectively (default: 1e-30,1e-3)\n","  -mom, --momentum MOMENTUM\n","      if applicable, momentum value for optimizer. (default: 0)\n","  --nesterov NESTEROV\n","      if applicable, whether to use nesterov momentum. (default: True)\n","  -nu, --nus NUS\n","      if applicable, nu value(s) for optimizer. can use a single value like 0.7\n","      or a comma-separated tuple like 0.7,1.0 (default: 0.7)\n","  -beta, --betas BETAS\n","      if applicable, beta value(s) for optimizer. can use a single value like\n","      0.9 or a comma-separated tuple like 0.9,0.999 (default: 0.9,0.999)\n","  -wdecay, --weight-decay WEIGHT_DECAY\n","      Weight decay on the weights. (default: None)\n","\n","BPEHelper Arguments:\n","  --bpe-vocab BPE_VOCAB\n","      path to pre-trained tokenizer vocab (default: None)\n","  --bpe-merge BPE_MERGE\n","      path to pre-trained tokenizer merge (default: None)\n","\n","Learning Rate Scheduler:\n","  --lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}\n","      Learning rate scheduler. (default: reduceonplateau)\n","  --lr-scheduler-patience LR_SCHEDULER_PATIENCE\n","      LR scheduler patience. In number of validation runs. If using fixed\n","      scheduler, LR is decayed every <patience> validations. (default: 3)\n","  --lr-scheduler-decay LR_SCHEDULER_DECAY\n","      Decay factor for LR scheduler, or how much LR is multiplied by when it is\n","      lowered. (default: 0.5)\n","  --max-lr-steps MAX_LR_STEPS\n","      Number of train steps the scheduler should take after warmup. Training is\n","      terminated after this many steps. This should only be set for --lr-\n","      scheduler cosine or linear (default: -1)\n","  --invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA\n","      Constant used only to find the lr multiplier for the invsqrt scheduler.\n","      Must be set for --lr-scheduler invsqrt (default: -1)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EKGUWyKTwVtX"},"source":["You'll notice the options are give as commandline arguments. We control our options via `argparse`. The option names are relatively predictable: `--init-model` becomes `init_model`; `--num-epochs` becomes `num_epochs` and so on."]},{"cell_type":"markdown","metadata":{"id":"jgLwGAq1wZJb"},"source":["# Looking at model predictions\n","\n","We have shown how we can chat with a model ourselves, interactively. We might want to inspect how the model reacts with a fixed set of inputs. Let's use that model we just trained!\n"]},{"cell_type":"code","metadata":{"id":"UCZgs6OlvJ-q","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1587094716843,"user_tz":240,"elapsed":8955,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"95b89fa8-22a6-4261-d72e-e82b07517810"},"source":["from parlai.scripts.display_model import DisplayModel\n","DisplayModel.main(\n","    task='empathetic_dialogues',\n","    model_file='from_pretrained/model',\n","    num_examples=2,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ warning: overriding opt['num_examples'] to 2 (previously: None )]\n","[ Using CUDA ]\n","Dictionary: loading dictionary from from_pretrained/model.dict\n","[ num words =  54944 ]\n","Total parameters: 87,508,992 (87,508,992 trainable)\n","[ Loading existing model params from from_pretrained/model ]\n","[creating task(s): empathetic_dialogues]\n","[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n","\u001b[0mToday,as i was leaving for work in the morning,i had a tire burst in the middle of a busy road. That scared the hell out of me!\u001b[0;0m\n","\u001b[1;94m    labels: Are you fine now?\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n","\u001b[0mYeah,i'm doing alright now, but with minor injuries.\u001b[0;0m\n","\u001b[1;94m    labels: Cool :) Is your car damaged a lot?\u001b[0;0m\n","\u001b[0;95m     model: No response\u001b[0;0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2H3QKTjdwokh"},"source":["Whoa wait a second! The model isn't giving any responses? That's because we set `--skip-generation true` to speed up training. We need to turn that back off."]},{"cell_type":"code","metadata":{"id":"DLiq-vuowamh","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1587094724589,"user_tz":240,"elapsed":5544,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"241342eb-6ac6-4a0c-91c5-674ab6b7e0c7"},"source":["from parlai.scripts.display_model import DisplayModel\n","DisplayModel.main(\n","    task='empathetic_dialogues',\n","    model_file='from_pretrained/model',\n","    num_examples=2,\n","    skip_generation=False,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ warning: overriding opt['num_examples'] to 2 (previously: None )]\n","[ warning: overriding opt['skip_generation'] to False (previously: True )]\n","[ Using CUDA ]\n","Dictionary: loading dictionary from from_pretrained/model.dict\n","[ num words =  54944 ]\n","Total parameters: 87,508,992 (87,508,992 trainable)\n","[ Loading existing model params from from_pretrained/model ]\n","[creating task(s): empathetic_dialogues]\n","[EmpatheticDialoguesTeacher] Only use experiencer side? True, datatype: valid\n","\u001b[1;31m- - - NEW EPISODE: empathetic_dialogues- - -\u001b[0;0m\n","\u001b[0mToday,as i was leaving for work in the morning,i had a tire burst in the middle of a busy road. That scared the hell out of me!\u001b[0;0m\n","\u001b[1;94m    labels: Are you fine now?\u001b[0;0m\n","\u001b[0;95m     model: oh no ! that ' s terrible ! did you get a new tire ?\u001b[0;0m\n","\u001b[0mYeah,i'm doing alright now, but with minor injuries.\u001b[0;0m\n","\u001b[1;94m    labels: Cool :) Is your car damaged a lot?\u001b[0;0m\n","\u001b[0;95m     model: that ' s good . i hope you are okay .\u001b[0;0m\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-MR0rn0ZwyxQ"},"source":["On the command line:\n","```bash\n","python -m parlai.scripts.display_model --task empathetic_dialogues --model-file zoo:tutorial_transformer_generator/model\n","```"]},{"cell_type":"markdown","metadata":{"id":"jYuaSPWrw0Il"},"source":["# Bringing your own datasets\n","\n","What if you want to build your own dataset in ParlAI? Of course you can do that!"]},{"cell_type":"code","metadata":{"id":"5SgJi8XHwtph","colab":{"base_uri":"https://localhost:8080/","height":323},"executionInfo":{"status":"ok","timestamp":1587094731661,"user_tz":240,"elapsed":380,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"9656b678-9dfc-4cfa-d1eb-3cb13aa14608"},"source":["from parlai.core.teachers import register_teacher, DialogTeacher\n","\n","@register_teacher(\"my_teacher\")\n","class MyTeacher(DialogTeacher):\n","    def __init__(self, opt, shared=None):\n","        # opt is the command line arguments.\n","\n","        # What is this shared thing?\n","        # We make many copies of a teacher, one-per-batchsize. Shared lets us store\n","\n","        # We just need to set the \"datafile\".  This is boilerplate, but differs in many teachers.\n","        # The \"datafile\" is the filename where we will load the data from. In this case, we'll set it to\n","        # the fold name (train/valid/test) + \".txt\"\n","        opt['datafile'] = opt['datatype'].split(':')[0] + \".txt\"\n","        super().__init__(opt, shared)\n","\n","    def setup_data(self, datafile):\n","        # filename tells us where to load from.\n","        # We'll just use some hardcoded data, but show how you could read the filename here:\n","        print(f\" ~~ Loading from {datafile} ~~ \")\n","\n","        # setup_data should yield tuples of ((text, label), new_episode)\n","        # That is ((str, str), bool)\n","\n","        # first episode\n","        # notice how we have call, response, and then True? The True indicates this is a first message\n","        # in a conversation\n","        yield ('Hello', 'Hi'), True\n","        # Next we have the second turn. This time, the last element is False, indicating we're still going\n","        yield ('How are you', 'I am fine'), False\n","        yield (\"Let's say goodbye\", 'Goodbye!'), False\n","\n","        # second episode. We need to have True again!\n","        yield (\"Hey\", \"hi there\"), True\n","        yield (\"Deja vu?\", \"Deja vu!\"), False\n","        yield (\"Last chance\", \"This is it\"), False\n","\n","\n","DisplayData.main(task=\"my_teacher\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[creating task(s): my_teacher]\n"," ~~ Loading from train.txt ~~ \n","\u001b[1;31m- - - NEW EPISODE: my_teacher - - -\u001b[0;0m\n","\u001b[0mHello\u001b[0;0m\n","   \u001b[1;94mHi\u001b[0;0m\n","\u001b[0mHow are you\u001b[0;0m\n","   \u001b[1;94mI am fine\u001b[0;0m\n","\u001b[0mLet's say goodbye\u001b[0;0m\n","   \u001b[1;94mGoodbye!\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: my_teacher - - -\u001b[0;0m\n","\u001b[0mHey\u001b[0;0m\n","   \u001b[1;94mhi there\u001b[0;0m\n","\u001b[0mDeja vu?\u001b[0;0m\n","   \u001b[1;94mDeja vu!\u001b[0;0m\n","\u001b[0mLast chance\u001b[0;0m\n","   \u001b[1;94mThis is it\u001b[0;0m\n","EPOCH DONE\n","[ loaded 2 episodes with a total of 6 examples ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vvwxi6gXw8jU"},"source":["Notice how the data corresponds to the utterances we provided? In reality, we'd normally want to load up a data file, loop through it, and yield the tuples from processed data. But for this simple example, it works well.\n","\n","We can now use our teacher in the standard places! Let's see how the model we trained earlier behaves with it:"]},{"cell_type":"code","metadata":{"id":"ZIyZQnxAw5HG","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1587094741413,"user_tz":240,"elapsed":5464,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"7240d04f-f9d3-4188-9bc8-c67f99b873b5"},"source":["DisplayModel.main(task='my_teacher', model_file='from_pretrained/model', skip_generation=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ warning: overriding opt['task'] to my_teacher (previously: empathetic_dialogues )]\n","[ warning: overriding opt['skip_generation'] to False (previously: True )]\n","[ Using CUDA ]\n","Dictionary: loading dictionary from from_pretrained/model.dict\n","[ num words =  54944 ]\n","Total parameters: 87,508,992 (87,508,992 trainable)\n","[ Loading existing model params from from_pretrained/model ]\n","[creating task(s): my_teacher]\n"," ~~ Loading from valid.txt ~~ \n","\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n","\u001b[0mHello\u001b[0;0m\n","\u001b[1;94m    labels: Hi\u001b[0;0m\n","\u001b[0;95m     model: hi\u001b[0;0m\n","\u001b[0mHow are you\u001b[0;0m\n","\u001b[1;94m    labels: I am fine\u001b[0;0m\n","\u001b[0;95m     model: i am good , how are you ?\u001b[0;0m\n","\u001b[0mLet's say goodbye\u001b[0;0m\n","\u001b[1;94m    labels: Goodbye!\u001b[0;0m\n","\u001b[0;95m     model: i am fine\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n","\u001b[0mHey\u001b[0;0m\n","\u001b[1;94m    labels: hi there\u001b[0;0m\n","\u001b[0;95m     model: hi\u001b[0;0m\n","\u001b[0mDeja vu?\u001b[0;0m\n","\u001b[1;94m    labels: Deja vu!\u001b[0;0m\n","\u001b[0;95m     model: i ' ve just been in this place before\u001b[0;0m\n","\u001b[0mLast chance\u001b[0;0m\n","\u001b[1;94m    labels: This is it\u001b[0;0m\n","\u001b[0;95m     model: i ' ve just been in this place before\u001b[0;0m\n","EPOCH DONE\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EOzvSHAy0meK"},"source":["Note that the `register_teacher` decorator makes the commands aware of your teacher. If you leave it off, the commands won't be able to locate it. If you want to use your teacher on the command line, you'll need to put it in a very specific filename: `parlai/agents/my_teacher/agents.py`, and you'll need to name the class `DefaultTeacher` instead of `MyTeacher`."]},{"cell_type":"markdown","metadata":{"id":"nJj7Lhs00oOB"},"source":["# Creating your own models\n","\n","As a start, we'll implement a *very* simple agent. This agent will just sort of respond with \"hello X, my name is Y\", where X is based on the input"]},{"cell_type":"code","metadata":{"id":"pykhtFDrxCPo"},"source":["from parlai.core.agents import register_agent, Agent\n","\n","@register_agent(\"hello\")\n","class HelloAgent(Agent):\n","    @classmethod\n","    def add_cmdline_args(cls, parser, partial_opt):\n","        parser.add_argument('--name', type=str, default='Alice', help=\"The agent's name.\")\n","        return parser\n","\n","    def __init__(self, opt, shared=None):\n","        # similar to the teacher, we have the Opt and the shared memory objects!\n","        super().__init__(opt, shared)\n","        self.id = 'HelloAgent'\n","        self.name = opt['name']\n","\n","    def observe(self, observation):\n","        # Gather the last word from the other user's input\n","        words = observation.get('text', '').split()\n","        if words:\n","            self.last_word = words[-1]\n","        else:\n","            self.last_word = \"stranger!\"\n","\n","    def act(self):\n","        # Always return a string like this.\n","        return {\n","            'id': self.id,\n","            'text': f\"Hello {self.last_word}, I'm {self.name}\",\n","        }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x1SZmy_s0sGd"},"source":["Let's try seeing how this agent behaves:"]},{"cell_type":"code","metadata":{"id":"HcS1UIFH0pb6","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"ok","timestamp":1587094744069,"user_tz":240,"elapsed":640,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"bcc52fbf-49f8-47ed-e5db-09e5b6c57b54"},"source":["DisplayModel.main(task='my_teacher', model='hello')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[creating task(s): my_teacher]\n"," ~~ Loading from valid.txt ~~ \n","\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n","\u001b[0mHello\u001b[0;0m\n","\u001b[1;94m    labels: Hi\u001b[0;0m\n","\u001b[0;95m     model: Hello Hello, I'm Alice\u001b[0;0m\n","\u001b[0mHow are you\u001b[0;0m\n","\u001b[1;94m    labels: I am fine\u001b[0;0m\n","\u001b[0;95m     model: Hello you, I'm Alice\u001b[0;0m\n","\u001b[0mLet's say goodbye\u001b[0;0m\n","\u001b[1;94m    labels: Goodbye!\u001b[0;0m\n","\u001b[0;95m     model: Hello goodbye, I'm Alice\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n","\u001b[0mHey\u001b[0;0m\n","\u001b[1;94m    labels: hi there\u001b[0;0m\n","\u001b[0;95m     model: Hello Hey, I'm Alice\u001b[0;0m\n","\u001b[0mDeja vu?\u001b[0;0m\n","\u001b[1;94m    labels: Deja vu!\u001b[0;0m\n","\u001b[0;95m     model: Hello vu?, I'm Alice\u001b[0;0m\n","\u001b[0mLast chance\u001b[0;0m\n","\u001b[1;94m    labels: This is it\u001b[0;0m\n","\u001b[0;95m     model: Hello chance, I'm Alice\u001b[0;0m\n","EPOCH DONE\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PmvcRSGS0wQE"},"source":["Notice how it read the words from the user, and provides its name from the command line argument? We can also interact with it easily enough."]},{"cell_type":"code","metadata":{"id":"_xd5CaG00tv6","colab":{"base_uri":"https://localhost:8080/","height":680},"executionInfo":{"status":"ok","timestamp":1587094765570,"user_tz":240,"elapsed":17746,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"4d9aee8c-d390-46c7-e685-febcd5a5b91c"},"source":["Interactive.main(model='hello', name='Bob')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ optional arguments: ] \n","[  display_examples: False ]\n","[  display_ignore_fields: label_candidates,text_candidates ]\n","[  display_prettify: False ]\n","[  interactive_task: True ]\n","[  name: Bob ]\n","[ Main ParlAI Arguments: ] \n","[  batchsize: 1 ]\n","[  datapath: /usr/local/lib/python3.6/dist-packages/data ]\n","[  datatype: train ]\n","[  download_path: /usr/local/lib/python3.6/dist-packages/downloads ]\n","[  dynamic_batching: None ]\n","[  hide_labels: False ]\n","[  image_mode: raw ]\n","[  init_opt: None ]\n","[  multitask_weights: [1] ]\n","[  numthreads: 1 ]\n","[  show_advanced_args: False ]\n","[  task: interactive ]\n","[ ParlAI Model Arguments: ] \n","[  dict_class: None ]\n","[  init_model: None ]\n","[  model: hello ]\n","[  model_file: None ]\n","[ Local Human Arguments: ] \n","[  local_human_candidates_file: None ]\n","[  single_turn: False ]\n","[ ParlAI Image Preprocessing Arguments: ] \n","[  image_cropsize: 224 ]\n","[  image_size: 256 ]\n","\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n","[creating task(s): interactive]\n","\u001b[0mEnter Your Message:\u001b[0;0m hi, who are you?\n","\u001b[0;34m[HelloAgent]:\u001b[0;0m \u001b[1mHello you?, I'm Bob\u001b[0;0m\n","\u001b[0mEnter Your Message:\u001b[0;0m My name is Stephen\n","\u001b[0;34m[HelloAgent]:\u001b[0;0m \u001b[1mHello Stephen, I'm Bob\u001b[0;0m\n","\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n","\u001b[0;34m[HelloAgent]:\u001b[0;0m \u001b[1mHello stranger!, I'm Bob\u001b[0;0m\n","CHAT DONE \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qAe1hytf1BPk"},"source":["Similar to the teacher, the call to `register_agent` makes it available for use in commands. If you forget the `register_agent` decorator, you won't be able to refer to it. Similarly, if you wanted to use this model from the command line, you would need to save this code to a special folder: `parlai/agents/hello/hello.py`."]},{"cell_type":"markdown","metadata":{"id":"8aBbhKTO1DEE"},"source":["## Creating a neural network model\n","\n","The base Agent class is very simple, but it also provides extremely little functionality. We have created solid abstractions for creating neural-network type models. [`TorchGeneratorAgent`](https://parl.ai/docs/torch_agent.html#module-parlai.core.torch_generator_agent) is one our common abstractions, and it assumes a model which outputs one-word-at-a-time.\n","\n","The following is from our [ExampleSeq2Seq](https://github.com/facebookresearch/ParlAI/blob/master/parlai/agents/examples/seq2seq.py) agent. It's a simple RNN model, trained like a Machine Translation model. The Model is too complex to go over in this document, but please feel free to [read our TorchGeneratorAgent tutorial](https://parl.ai/docs/tutorial_torch_generator_agent.html)."]},{"cell_type":"code","metadata":{"id":"hVrZh-T903wh"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import parlai.core.torch_generator_agent as tga\n","\n","\n","class Encoder(nn.Module):\n","    \"\"\"\n","    Example encoder, consisting of an embedding layer and a 1-layer LSTM with the\n","    specified hidden size.\n","    Pay particular attention to the ``forward`` output.\n","    \"\"\"\n","\n","    def __init__(self, embeddings, hidden_size):\n","        \"\"\"\n","        Initialization.\n","        Arguments here can be used to provide hyperparameters.\n","        \"\"\"\n","        # must call super on all nn.Modules.\n","        super().__init__()\n","\n","        self.embeddings = embeddings\n","        self.lstm = nn.LSTM(\n","            input_size=hidden_size,\n","            hidden_size=hidden_size,\n","            num_layers=1,\n","            batch_first=True,\n","        )\n","\n","    def forward(self, input_tokens):\n","        \"\"\"\n","        Perform the forward pass for the encoder.\n","        Input *must* be input_tokens, which are the context tokens given\n","        as a matrix of lookup IDs.\n","        :param input_tokens:\n","            Input tokens as a bsz x seqlen LongTensor.\n","            Likely will contain padding.\n","        :return:\n","            You can return anything you like; it is will be passed verbatim\n","            into the decoder for conditioning. However, it should be something\n","            you can easily manipulate in ``reorder_encoder_states``.\n","            This particular implementation returns the hidden and cell states from the\n","            LSTM.\n","        \"\"\"\n","        embedded = self.embeddings(input_tokens)\n","        _output, hidden = self.lstm(embedded)\n","        return hidden\n","\n","\n","class Decoder(nn.Module):\n","    \"\"\"\n","    Basic example decoder, consisting of an embedding layer and a 1-layer LSTM with the\n","    specified hidden size. Decoder allows for incremental decoding by ingesting the\n","    current incremental state on each forward pass.\n","    Pay particular note to the ``forward``.\n","    \"\"\"\n","\n","    def __init__(self, embeddings, hidden_size):\n","        \"\"\"\n","        Initialization.\n","        Arguments here can be used to provide hyperparameters.\n","        \"\"\"\n","        super().__init__()\n","        self.embeddings = embeddings\n","        self.lstm = nn.LSTM(\n","            input_size=hidden_size,\n","            hidden_size=hidden_size,\n","            num_layers=1,\n","            batch_first=True,\n","        )\n","\n","    def forward(self, input, encoder_state, incr_state=None):\n","        \"\"\"\n","        Run forward pass.\n","        :param input:\n","            The currently generated tokens from the decoder.\n","        :param encoder_state:\n","            The output from the encoder module.\n","        :parm incr_state:\n","            The previous hidden state of the decoder.\n","        \"\"\"\n","        embedded = self.embeddings(input)\n","        if incr_state is None:\n","            # this is our very first call. We want to seed the LSTM with the\n","            # hidden state of the decoder\n","            state = encoder_state\n","        else:\n","            # We've generated some tokens already, so we can reuse the existing\n","            # decoder state\n","            state = incr_state\n","\n","        # get the new output and decoder incremental state\n","        output, incr_state = self.lstm(embedded, state)\n","\n","        return output, incr_state\n","\n","\n","class ExampleModel(tga.TorchGeneratorModel):\n","    \"\"\"\n","    ExampleModel implements the abstract methods of TorchGeneratorModel to define how to\n","    re-order encoder states and decoder incremental states.\n","    It also instantiates the embedding table, encoder, and decoder, and defines the\n","    final output layer.\n","    \"\"\"\n","\n","    def __init__(self, dictionary, hidden_size=1024):\n","        super().__init__(\n","            padding_idx=dictionary[dictionary.null_token],\n","            start_idx=dictionary[dictionary.start_token],\n","            end_idx=dictionary[dictionary.end_token],\n","            unknown_idx=dictionary[dictionary.unk_token],\n","        )\n","        self.embeddings = nn.Embedding(len(dictionary), hidden_size)\n","        self.encoder = Encoder(self.embeddings, hidden_size)\n","        self.decoder = Decoder(self.embeddings, hidden_size)\n","\n","    def output(self, decoder_output):\n","        \"\"\"\n","        Perform the final output -> logits transformation.\n","        \"\"\"\n","        return F.linear(decoder_output, self.embeddings.weight)\n","\n","    def reorder_encoder_states(self, encoder_states, indices):\n","        \"\"\"\n","        Reorder the encoder states to select only the given batch indices.\n","        Since encoder_state can be arbitrary, you must implement this yourself.\n","        Typically you will just want to index select on the batch dimension.\n","        \"\"\"\n","        h, c = encoder_states\n","        return h[:, indices, :], c[:, indices, :]\n","\n","    def reorder_decoder_incremental_state(self, incr_state, indices):\n","        \"\"\"\n","        Reorder the decoder states to select only the given batch indices.\n","        This method can be a stub which always returns None; this will result in the\n","        decoder doing a complete forward pass for every single token, making generation\n","        O(n^2). However, if any state can be cached, then this method should be\n","        implemented to reduce the generation complexity to O(n).\n","        \"\"\"\n","        h, c = incr_state\n","        return h[:, indices, :], c[:, indices, :]\n","\n","\n","@register_agent(\"my_first_lstm\")\n","class Seq2seqAgent(tga.TorchGeneratorAgent):\n","    \"\"\"\n","    Example agent.\n","    Implements the interface for TorchGeneratorAgent. The minimum requirement is that it\n","    implements ``build_model``, but we will want to include additional command line\n","    parameters.\n","    \"\"\"\n","\n","    @classmethod\n","    def add_cmdline_args(cls, argparser, partial_opt):\n","        \"\"\"\n","        Add CLI arguments.\n","        \"\"\"\n","        # Make sure to add all of TorchGeneratorAgent's arguments\n","        super().add_cmdline_args(argparser)\n","\n","        # Add custom arguments only for this model.\n","        group = argparser.add_argument_group('Example TGA Agent')\n","        group.add_argument(\n","            '-hid', '--hidden-size', type=int, default=1024, help='Hidden size.'\n","        )\n","\n","    def build_model(self):\n","        \"\"\"\n","        Construct the model.\n","        \"\"\"\n","\n","        model = ExampleModel(self.dict, self.opt['hidden_size'])\n","        # Optionally initialize pre-trained embeddings by copying them from another\n","        # source: GloVe, fastText, etc.\n","        self._copy_embeddings(model.embeddings.weight, self.opt['embedding_type'])\n","        return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vfR9w_Hm1HHY"},"source":["Of course, now we can train with our new model. Let's train it on our toy task that we created earlier."]},{"cell_type":"code","metadata":{"id":"SJMXpogz1E-_","colab":{"base_uri":"https://localhost:8080/","height":952},"executionInfo":{"status":"ok","timestamp":1587094786871,"user_tz":240,"elapsed":13011,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"3fe8275b-a7cd-491a-a761-fbd5849e2a7c"},"source":["# of course, we can train the model! Let's Train it on our silly toy task from above\n","!rm -rf my_first_lstm\n","!mkdir -p my_first_lstm\n","\n","TrainModel.main(\n","    model='my_first_lstm',\n","    model_file='my_first_lstm/model',\n","    task='my_teacher',\n","    batchsize=1,\n","    validation_every_n_secs=10,\n","    max_train_time=60,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Building dictionary: 100%|██████████| 6.00/6.00 [00:00<00:00, 1.91kex/s]"],"name":"stderr"},{"output_type":"stream","text":["[ building dictionary first... ]\n","[creating task(s): my_teacher]\n"," ~~ Loading from train.txt ~~ \n"," ~~ Loading from train.txt ~~ \n","Dictionary: saving dictionary to my_first_lstm/model.dict\n","[ dictionary built with 30 tokens in 0s ]\n","[ no model with opt yet at: my_first_lstm/model(.opt) ]\n","[ Using CUDA ]\n","Dictionary: loading dictionary from my_first_lstm/model.dict\n","[ num words =  30 ]\n","Total parameters: 16,824,320 (16,824,320 trainable)\n","[creating task(s): my_teacher]\n"," ~~ Loading from train.txt ~~ \n","[ training... ]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["[ time:10.0s total_exs:1828 epochs:304.67 ]\n","     clip  exs  gnorm  gpu_mem   loss  lr   ppl  token_acc  total_train_updates   tpb  updates\n","   .01641 1828  1.368    .9171 .04105   1 1.042      .9942                 1828 3.328     1828\n","\n","[ time:10.0s total_exs:1828 epochs:304.67 ]\n","    gpu_mem  lr  total_train_updates\n","      .9171   1                 1828\n","\n","[creating task(s): my_teacher]\n"," ~~ Loading from valid.txt ~~ \n","[ running eval: valid ]\n","[ eval completed in 0.06s ]\n","valid:\n","    accuracy   bleu-4  exs  f1  gpu_mem  loss  lr  ppl  token_acc  total_train_updates   tpb\n","           1 .0003337    6   1    .9171     0   1    1          1                 1828 3.333\n","\n","[ new best accuracy: 1 ]\n","[ saving best valid model: my_first_lstm/model ]\n","[ task solved! stopping. ]\n","[ Using CUDA ]\n","Dictionary: loading dictionary from my_first_lstm/model.dict\n","[ num words =  30 ]\n","Total parameters: 16,824,320 (16,824,320 trainable)\n","[ Loading existing model params from my_first_lstm/model ]\n","[creating task(s): my_teacher]\n"," ~~ Loading from valid.txt ~~ \n","[ running eval: valid ]\n","[ eval completed in 0.05s ]\n","valid:\n","    accuracy   bleu-4  exs  f1  gpu_mem  loss  lr  ppl  token_acc  total_train_updates   tpb\n","           1 .0003337    6   1    .9131     0   1    1          1                 1828 3.333\n","\n","[creating task(s): my_teacher]\n"," ~~ Loading from test.txt ~~ \n","[ running eval: test ]\n","[ eval completed in 0.05s ]\n","test:\n","    accuracy   bleu-4  exs  f1  gpu_mem  loss  lr  ppl  token_acc  total_train_updates   tpb\n","           1 .0003337    6   1    .9131     0   1    1          1                 1828 3.333\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8hHrruVd1KnK"},"source":["Let's see how it does. It should reproduce the data perfectly:"]},{"cell_type":"code","metadata":{"id":"shqFpdrE1Iif","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1587094787187,"user_tz":240,"elapsed":8430,"user":{"displayName":"Stephen Roller","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_Yz2XJi9tFpvdZ8eXeJmXRavueQWUrUYhr1g9Kw=s64","userId":"16998712455997354732"}},"outputId":"1a89571c-2a42-48b8-9752-dffc4a58e557"},"source":["DisplayModel.main(model_file='my_first_lstm/model', task='my_teacher')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ Using CUDA ]\n","Dictionary: loading dictionary from my_first_lstm/model.dict\n","[ num words =  30 ]\n","Total parameters: 16,824,320 (16,824,320 trainable)\n","[ Loading existing model params from my_first_lstm/model ]\n","[creating task(s): my_teacher]\n"," ~~ Loading from valid.txt ~~ \n","\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n","\u001b[0mHello\u001b[0;0m\n","\u001b[1;94m    labels: Hi\u001b[0;0m\n","\u001b[0;95m     model: Hi\u001b[0;0m\n","\u001b[0mHow are you\u001b[0;0m\n","\u001b[1;94m    labels: I am fine\u001b[0;0m\n","\u001b[0;95m     model: I am fine\u001b[0;0m\n","\u001b[0mLet's say goodbye\u001b[0;0m\n","\u001b[1;94m    labels: Goodbye!\u001b[0;0m\n","\u001b[0;95m     model: Goodbye !\u001b[0;0m\n","\u001b[1;31m- - - NEW EPISODE: my_teacher- - -\u001b[0;0m\n","\u001b[0mHey\u001b[0;0m\n","\u001b[1;94m    labels: hi there\u001b[0;0m\n","\u001b[0;95m     model: hi there\u001b[0;0m\n","\u001b[0mDeja vu?\u001b[0;0m\n","\u001b[1;94m    labels: Deja vu!\u001b[0;0m\n","\u001b[0;95m     model: Deja vu !\u001b[0;0m\n","\u001b[0mLast chance\u001b[0;0m\n","\u001b[1;94m    labels: This is it\u001b[0;0m\n","\u001b[0;95m     model: This is it\u001b[0;0m\n","EPOCH DONE\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3hzrDhPS1QCW"},"source":["Unsurprisingly, we got perfect accuracy. This is because the data set is only a handful of utterances, and we can perfectly memorize it in this LSTM. Nonetheless, a great success!\n","\n","# What's next!\n","\n","The sky's the limit! Be sure to check out our [GitHub](https://github.com/facebookresearch/ParlAI) and [Follow ParlAI on Twitter](https://twitter.com/parlai_parley). We're eager to hear what you are using ParlAI for!\n","\n","Here are some other great resources:\n","- [Our research page](https://parl.ai/projects/)\n","- [ParlAI Documentations](https://parl.ai/docs/index.html)\n","- [Tutorial: Writing a Ranker model](https://parl.ai/docs/tutorial_torch_ranker_agent.html)\n","- [Tutorial: Using Mechanical Turk](https://parl.ai/docs/tutorial_mturk.html)\n","- [Tutorial: Connecting to chat services](https://parl.ai/docs/tutorial_chat_service.html)"]}]}